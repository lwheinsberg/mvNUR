[
  {
    "objectID": "prep.html",
    "href": "prep.html",
    "title": "2  Data preparation",
    "section": "",
    "text": "2.1 Overview\nA fully synthetic example data set has been created to accompany this repository so that we can freely and safely share it without restriction on GitHub in order to document the analytical steps and interpretation related to our two exemplar multivariate Bayesian approaches. The real data from which the synthetic data were generated were collected via a nurse-led study from the University of Pittsburgh focused on individuals with breast cancer. The study collected extensive data related to symptoms, and a sub-study collected candidate gene single nucleotide polymorphism (SNP) data. Candidate symptoms selected for inclusion in this tutorial included anxiety, depression, fatigue, daytime sleepiness, cognitive function, and pain. Candidate SNPs selected for examination in this study included rs4880, rs5746136, rs1041740, rs10432782, rs4135225, and rs7522705. The original data set consisted of 110 participants. For the purposes of our examples, a larger, synthetic data set mirroring the statistical properties of the original data set was created. The data set contains 770 participants.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "prep.html#load-libraries",
    "href": "prep.html#load-libraries",
    "title": "2  Data preparation",
    "section": "2.2 Load libraries",
    "text": "2.2 Load libraries\nLoad the libraries needed to run the code.\n\nlibrary(tidyverse) ## Data wrangling \nlibrary(pander) ## Table formatting \nlibrary(preprocessCore) ## Preprocessing functions\n#if (!require(\"BiocManager\", quietly = TRUE))\n#    install.packages(\"BiocManager\") ## Facilitate installation of preprocessCore\n#BiocManager::install(\"preprocessCore\") \n# Note: `preprocessCore` isn't available for R version 4.3.1, but can be installed using `biocManager` https://bioconductor.org/packages/release/bioc/html/preprocessCore.html\nlibrary(corrplot) ## Visualize correlation matrix",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "prep.html#prepare-data-for-multiariate-analyses",
    "href": "prep.html#prepare-data-for-multiariate-analyses",
    "title": "2  Data preparation",
    "section": "2.3 Prepare data for multiariate analyses",
    "text": "2.3 Prepare data for multiariate analyses\nThe programs we will use for multivariate analyses (bnlearn and mvBIMBAM) require the data to be in a specific format for analysis. In this markdown, we are preparing and formatting the data for analysis.\n\n2.3.1 Read in the synthetic data set\nPlease see the README.md for information regarding the example synthetic data set.\n\n# Read in the synthetic data set created for use with this example analysis code\ndf_synth &lt;- read.csv(\"data/BrCa_synthetic.csv\") ###CUSTOMIZE**\nhead(df_synth)\n\n    ID EMO_tscore bdito FAT_tscore paohcif EPSscore pain age education race\n1 1000       47.8     8       46.9       0        5    0  60        18    0\n2 1001       47.8     8       49.2       4       12    3  51        21    0\n3 1002       49.4    18       50.4      16       12    1  57        20    0\n4 1003       45.9     3       38.5       6        2    0  51        16    0\n5 1004       50.8     6       46.9       0        7    1  63        16    0\n6 1005       37.1     0       38.5       0        2    1  59        15    0\n  rs4880 rs5746136 rs1041740 rs10432782 rs4135225 rs7522705\n1      1         0         1          1         1         1\n2      2         1         0          1         0         2\n3      2         1         0          0         0         0\n4      1         1         0          0         1         1\n5      0         1         1          0         1         0\n6      1         0         0          0         1         1\n\n(n &lt;- nrow(df_synth))\n\n[1] 770\n\n# Define the phenotypes (in this case, symptoms) of interest and mapping names \ntraits &lt;- c(\"EMO_tscore\", \"bdito\", \"FAT_tscore\", \"paohcif\", \"EPSscore\", \"pain\") ###CUSTOMIZE**\n# Define a trait mapping object to create custom labels for figures \n# (e.g., EMO_tscore variable represents our measure of Anxiety; bdito represents our measure of depression; etc.)\ntrait_mapping &lt;- c(\"Anxiety\", \"Depression\", \"Fatigue\", \"Cognitive function\", \"Sleepiness\", \"Pain\") ###CUSTOMIZE**\n\n# Create custom labels \ncustom_labels &lt;- setNames(trait_mapping, traits)\n\n# Define variants of interest \ngenes &lt;- c(\"rs4880\", \"rs5746136\", \"rs1041740\", \"rs10432782\", \"rs4135225\", \"rs7522705\") ###CUSTOMIZE**\n\n# Create expanded custom labels \ncustom_labels2 &lt;- c(custom_labels, setNames(genes, genes))\n\n# Create a mapping of node types (for bnlearn)\ndf_vertex_table &lt;- data.frame(\n  vertex.names = c(trait_mapping, genes),\n  type = rep(c(\"Symptom\", \"Genotype\"), each = length(traits)),\n  stringsAsFactors = FALSE\n)\n\nCheck that all variables are numeric or integer.\n\nrs_columns &lt;- grep(\"^rs\", names(df_synth), value = TRUE)\nnon_numeric_rs_columns &lt;- rs_columns[!sapply(df_synth[rs_columns], is.numeric)]\nif (length(non_numeric_rs_columns) &gt; 0) {\n  cat(\"SAFETY CHECK WARNING: The following variables starting with 'rs' are not numeric:\", paste(non_numeric_rs_columns, collapse = \", \"), \"\\n\")\n} else {\n  cat(\"SAFETY CHECK PASSED: All 'rs' variables are numeric.\\n\")\n}\n\nSAFETY CHECK PASSED: All 'rs' variables are numeric.\n\n\nIn brief, the data set focuses on 6 symptoms (EMO_tscore, bdito, FAT_tscore, paohcif, EPSscore, pain) and 6 candidate variants of interest (rs4880, rs5746136, rs1041740, rs10432782, rs4135225, rs7522705) and contains 770 participants.\n\n# Read in a mapping of variable name to informative label\ndict &lt;- read.csv(\"data/BrCa_synthetic_SimpleDict.csv\") ###CUSTOMIZE** (OPTIONAL)\npander(dict, \"Data dictionary\") \n\n\nData dictionary (continued below)\n\n\n\n\n\n\n\nVariable\nLabel\nDescription\n\n\n\n\nEmo_tscore\nAnxiety\nPROMIS Emotional Distress Anxiety (Short Form 8a) - 8 items measuring emotional distress and anxiety (panic, fearfulness, worry, dread, tension,nervousness, restlessness, and somatic symptoms including racing heart and dizziness) in the last 7 days. This instrument generates T-scores, which are standard scores with a mean of 50 and standard deviation of 10 in the U.S. general population. Higher T-scores indicate worse distress and anxiety. T-scores range from 10 to 90.\n\n\nbdito\nDepression\nThe Beck Depression Inventory-II - 21-items measuring severity of depression (i.e., grief, loss, flat affect, withdrawal, mania) over a two-week period. Scores range from 0 to 63, where high scores indicate higher levels or more severe depression.\n\n\nFAT_tscore\nFatigue\nPROMIS Fatigue (Short Form 8a) - 8 items measuring the experience of fatigue and the interference of fatigue on daily activities over the past 7 days. This instrument generates T-scores, which are standard scores with a mean of 50 and standard deviation of 10 in the U.S. general population. Higher T-scores indicate worse fatigue. T-scores range from 10 to 90.\n\n\npaohcif\nCognitive function\nPatient assessment of own cognitive functioning - 33 items measuring self-reported ‘recent’ cognitive function consisting of 5 dimensions: memory, language and communication, use of hands, sensory-perceptual, higher level cognitive and intellectual functioning. Higher scores indicate worse perceived cognitive functioning. Scores range from 0 to 155.\n\n\nEPSscore\nSleepiness\nEpworth Sleepiness Scale - 8 item scale measuring self-reported ‘recent’ daytime sleepiness. Higher score indicate greater daytime sleepiness. Scores range from 0 to 24.\n\n\npain\nPain\nBrief Pain Inventory (Short Form) - 9 items a widely used clinical tool for assessing pain (worst pain in the last 24 hours [0-10], least pain in the last 24 hours [0-10], pain on average [0-10], paing at the time of the interview [0-10], pain relief from treatment(s) in the last 24 hours [0%-100%]). Higher scores indicate higher levels of pain, each item ranges from 0-10.\n\n\nrs4880\nVariant 1\nSOD2 gene, hg19 postion chr6: 160113872\n\n\nrs5746136\nVariant 2\nSOD2 gene, hg19 postiion chr6: 160103084\n\n\nrs1041740\nVariant 3\nSOD1 gene, hg19 postiion chr21: 33040162\n\n\nrs10432782\nVariant 4\nSOD1 gene, hg19 postiion chr21: 33036391\n\n\nrs4135225\nVariant 5\nTXN gene, hg19 postiion chr9: 113006691\n\n\nrs7522705\nVariant 6\nPRDX1 gene, hg19 postiion chr1: 45992300\n\n\nrace\nRace\nSelf-identified race, 0=White, 1=Black\n\n\nage\nAge\nAge in years\n\n\neducation\nEducation\nSelf-reported years of education\n\n\n\n\n\n\n\n\n\n\nType\nCitation\n\n\n\n\nNumeric\nPilkonis, P.A. et al. (2011) Item banks for measureing emotional distress from the patient-reported outcomes measurement information system (PROMIS): Depression, Anxiety, and Anger, Assesssment, 18(3), 263-283\n\n\nNumeric\nBeck, A.T. et al. (1996) Beck Depression Inventory-II. San Antonio: The Psychological Corporation\n\n\nNumeric\nCell, D. et al. (2016) PROMIS fatigue item bank had clinical validity across diverse chronic conditions. Journal of Clinical Epidemiology, 73, 128-134\n\n\nNumeric\nChelune, G. J. et al. (1986) Neuropsychological and personality correlates of patients’ complaints of disability. Advances in clinical Neuropsychology, 1986:95-126\n\n\nNumeric\nJohns MW. A new method for measuring daytime sleepiness: The Epworth Sleepiness Scale. Sleep 1991; 14(6):540-5\n\n\nNumeric\nCleeland, C.S. et al. (2009). Pain assessment: Global use of the Brief Pain Inventory. Annals, Academy of Medicine, Sigapore, 23(2), 129-138.\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric, encoded value\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\n\n\n\n\n\n2.3.2 Examine correlation structure of the symptoms\n\n# Subset the dataset to include only the selected traits\nsubset_df &lt;- df_synth[traits]\n# Calculate the correlation matrix\ncor_matrix &lt;- cor(subset_df, use = \"complete.obs\")\n# Define custom labels for rows and columns\n# Update row and column names using custom labels\nrownames(cor_matrix) &lt;- custom_labels[rownames(cor_matrix)]\ncolnames(cor_matrix) &lt;- custom_labels[colnames(cor_matrix)]\n# Create a correlation plot\ncorrplot(cor_matrix, method = \"circle\", type = \"lower\", tl.col = \"black\", tl.srt = 45)\n\n\n\n\n\n\n\n\n\n\n2.3.3 Examine correlation structure of SNPs\n\n# Subset the dataset to include only the selected traits\nsubset_df &lt;- df_synth[genes]\n# Calculate the correlation matrix\ncor_matrix &lt;- cor(subset_df, use = \"complete.obs\")\n# Create a correlation plot\ncorrplot(cor_matrix, method = \"circle\", type = \"lower\", tl.col = \"black\", tl.srt = 45)\n\n\n\n\n\n\n\n\n\n\n2.3.4 Summarize missing data\n\nmissing_data_table &lt;- df_synth %&gt;%\n  summarise(across(everything(), ~sum(is.na(.)))) %&gt;% # Count NA values in each column\n  gather(key = \"Column\", value = \"Number_of_NAs\") %&gt;% # Convert to long format\n  arrange(desc(Number_of_NAs)) # Sort by the number of NAs\npander(missing_data_table)\n\n\n\n\n\n\n\n\nColumn\nNumber_of_NAs\n\n\n\n\nEMO_tscore\n7\n\n\nID\n0\n\n\nbdito\n0\n\n\nFAT_tscore\n0\n\n\npaohcif\n0\n\n\nEPSscore\n0\n\n\npain\n0\n\n\nage\n0\n\n\neducation\n0\n\n\nrace\n0\n\n\nrs4880\n0\n\n\nrs5746136\n0\n\n\nrs1041740\n0\n\n\nrs10432782\n0\n\n\nrs4135225\n0\n\n\nrs7522705\n0\n\n\n\n\n\n\n\n2.3.5 Clean up data\nFirst, let’s prepare our data sets. Currently, the software we are using does not allow missing data for multivariate phenotype analysis, so select complete cases only. We will also set up a few data frames in preparation to regress out variation related to our covariates of interest (in this example, age and race).\n\ndf_i1_regress: contains all variables of interest ordered and filtered for complete cases\n\ndf_i1: contains all variables except the covariates that will be regressed out below (in this example, age and race)\n\ndf_synth: Recode 0, 1, 2 genotypes to AA, AB, BB for later use in mvBIMBAM\n\n\n# The first data frame (df_i1_regress) contains all variables of interest ordered \n# and filtered for complete cases\ndf_i1_regress &lt;- df_synth %&gt;% \n  select(all_of(genes), \n         all_of(traits),\n         race, ###CUSTOMIZE** (covariate names, replacing age and race)\n         age) %&gt;% ###CUSTOMIZE** (covariate names, replacing age and race)\n  filter(complete.cases(.))\n(n &lt;- nrow(df_i1_regress))\n\n[1] 763\n\n# The second data frame (df_i1) contains all variables except the covariates that\n# will be regressed out (in this example, age and race)\ndf_i1 &lt;- df_i1_regress %&gt;% \n  select(all_of(genes), all_of(traits)) %&gt;% \n  filter(complete.cases(.))\n\n# Recode 0, 1, 2 genotypes to AA, AB, BB for later use in mvBIMBAM \ndf_synth &lt;- df_synth %&gt;% \n  mutate_at(\n    .vars = vars(starts_with(\"rs\")),\n    .funs = list(~ case_when(\n      . == 2 ~ \"BB\",\n      . == 1 ~ \"AB\",\n      . == 0 ~ \"AA\"\n    ))\n  )\n\n# Create Genotype (G) and Phenotype (Y) matrices\nG &lt;- as.matrix(df_i1 %&gt;% select(all_of(genes)))\nhead(G)\n\n     rs4880 rs5746136 rs1041740 rs10432782 rs4135225 rs7522705\n[1,]      1         0         1          1         1         1\n[2,]      2         1         0          1         0         2\n[3,]      2         1         0          0         0         0\n[4,]      1         1         0          0         1         1\n[5,]      0         1         1          0         1         0\n[6,]      1         0         0          0         1         1\n\nY &lt;- as.matrix(df_i1 %&gt;% select(all_of(traits)))\nhead(Y)\n\n     EMO_tscore bdito FAT_tscore paohcif EPSscore pain\n[1,]       47.8     8       46.9       0        5    0\n[2,]       47.8     8       49.2       4       12    3\n[3,]       49.4    18       50.4      16       12    1\n[4,]       45.9     3       38.5       6        2    0\n[5,]       50.8     6       46.9       0        7    1\n[6,]       37.1     0       38.5       0        2    1\n\n\nThere are 763 participants with complete data that we will retain for our analyses.\n\n\n2.3.6 Normalize and adjust data for covariates\nIn this example, we are adjusting our phenotypes of interest for the covariates age and race using ordinary linear regression models. If adapting this code for your own work, manually edit the covariate names in the f_quatile_norm_resid() function. Note that the sensitivity of the Bayesian multivariate mvBIMBAM framework to outlier values and non-normality also necessitates the normalization of phenotypes. As shown below, residualized phenotypes (i.e., adjusted for age/race) are order quantile-normalized.\n\n2.3.6.1 Create adjustment/normalization functions\nWe now create a function to perform residual adjustment for covariates (in this example, we are adjusting for age and race):\n\nf_quantile_norm_resid &lt;- function(Y, df) {\n  {o &lt;- apply(Y, 2, function(x) resid(lm(x ~ age + race, data = df)))} ###CUSTOMIZE** (covariate names, replacing age and race)\n  return(o)\n}\n\nIf adapting this code above for your own work, edit the x ~ age + race regression formula to adjust for covariates of interest, replacing age and race with your covariate variable names.\nWe now create function to ‘super quantile normalize’ the data:\n\nf_quantile_normalize_adjust &lt;- function(Y, data, ...) {\n  # Quantile normalize\n  Y_qn &lt;- normalize.quantiles(Y)\n  # Fit Y ~ age + race, extra residual (using function created above)\n  Y_qn_resid &lt;- f_quantile_norm_resid(Y = Y_qn, df = data, ...) \n  # Quantile normalize the residual\n  Y_qn_resid_qn &lt;- data.frame(normalize.quantiles(Y_qn_resid))\n  return(Y_qn_resid_qn)\n}\n\n\n\n2.3.6.2 Apply functions to perform normalization and covariate adjustment\n\n# Create a quantile normalized adjusted Y data frame (i.e., quantile normalization \n# and covariate adjustment is performed in one fell swoop)\nqn_resid_Y &lt;- f_quantile_normalize_adjust(Y, data = df_i1_regress)\n# Create a copy of this data frame for use later in this workflow \nqn_resid_Y_b &lt;- qn_resid_Y \n# Rename the columns of the quantile normalized data frame to match the \n# phenotypes of interest  \nnames(qn_resid_Y) &lt;- traits\nhead(qn_resid_Y)\n\n  EMO_tscore       bdito FAT_tscore   paohcif  EPSscore      pain\n1 -0.8851885  2.30362054  -3.330215 -5.645429 -3.414409 -6.012957\n2 -1.9542886  0.09188708  -3.221254 -1.577718  7.196097  1.066255\n3 -0.1561693  9.13047401  -2.133030 13.281734  8.530244 -3.592499\n4 -3.4144091 -6.10527417  -7.413173  1.066255 -8.598853 -7.199561\n5  1.8913640  0.83681075  -2.840231 -4.802835  1.891364 -1.847911\n6 -6.1052742 -8.14287258  -6.446351 -6.057697 -8.142873 -2.818185\n\n\nNote: For one test user (DM), the above chunk threw the error:\nError in normalize.quantiles(Y) : \nERROR; return code from pthread_create() is 22\nThis issue was resolved by updating Rstudio to the latest version.\n\n\n\n2.3.7 Remove outliers\nObservations in violation of multivariate normality at an alpha=0.01 level based on Mahalanobis distance-based test statistics are now removed to avoid spurious conclusions.\n\n2.3.7.1 Write a function to calculate Mahalanobis distance\n\n# Create a function to calculate Mahalanobis distance\ngetMD &lt;- function(x) {\n  Sx &lt;- cov(x)\n  m &lt;- mahalanobis(x, colMeans(x), Sx)\n  return(m)\n}\n\n\n\n2.3.7.2 Apply function to identify outliers\n\n# Drop individuals with data violating multivariate normality at alpha = 0.01\ni_keep &lt;- which(pchisq(getMD(qn_resid_Y_b), df = dim(Y)[2]) &gt; 0.01)\n\n\n\n\n2.3.8 Create a summary\n\n# Record sample sizes in a summary table\ntable1 &lt;- data.frame(study=rep(NA,1),N.traits=NA,N.variants=NA,N.total=NA,n.complete=NA,n.used=NA)\ni &lt;- 1\ntable1[i,\"study\"] &lt;- \"Study Name\" ###CUSTOMIZE** (study name)\ntable1[i,\"N.total\"] &lt;- nrow(df_synth)\ntable1[i,\"n.complete\"] &lt;- nrow(qn_resid_Y)\ntable1[i,\"n.used\"]  &lt;- nrow(qn_resid_Y[i_keep, ])\ntable1[i,\"N.traits\"] &lt;- ncol(qn_resid_Y)\ntable1[i,\"N.variants\"] &lt;- length(genes)\ntable1[i,]\n\n       study N.traits N.variants N.total n.complete n.used\n1 Study Name        6          6     770        763    763\n\n# Print number of observations due to violation of multivariate normality \ncat(dim(Y)[1] - length(i_keep), \" Obs removed due to violation of MV-Normality\")\n\n0  Obs removed due to violation of MV-Normality\n\n# Add to summary table\ntable1$n.removed &lt;- table1$N.total - table1$n.used\ntable1$percent.removed &lt;- round(100*table1$n.removed/table1$N.total,2)\n\n\npander(table1,caption=\"Sample sizes\")\n\n\nSample sizes (continued below)\n\n\n\n\n\n\n\n\n\n\n\nstudy\nN.traits\nN.variants\nN.total\nn.complete\nn.used\nn.removed\n\n\n\n\nStudy Name\n6\n6\n770\n763\n763\n7\n\n\n\n\n\n\n\n\n\npercent.removed\n\n\n\n\n0.91\n\n\n\n\n\n\n\n2.3.9 Prepare and save final files\n\n2.3.9.1 Data used in both programs\n\n# Check for data directory; if not present, create it \nif (!dir.exists(\"./data\")) {\n  dir.create(\"./data\")\n}\n\n# Write data \nsave(traits, genes, trait_mapping, custom_labels, custom_labels2, df_vertex_table, file = \"./data/TraitsGenes.RData\") ###CUSTOMIZE** (optional, file name)\n\n\n\n2.3.9.2 mvBIMBAM\n\n# Write phenotypes to a text file for use in mvBIMBAM \nif (!dir.exists(\"./inputs\")) {\n  dir.create(\"./inputs\")\n}\nwrite.table(round(qn_resid_Y[i_keep,], 8), \n            \"./inputs/pheno_bimbam.txt\", sep = \" \", ###CUSTOMIZE** (optional, file name)\n            row.names = F, col.names = F)\n\n# Refine genotype data for mvBIMBAM and write file\nGeno_write &lt;- df_synth %&gt;% select(all_of(genes), all_of(traits)) %&gt;%\n  filter(complete.cases(.)) %&gt;%\n  select(all_of(genes)) %&gt;%\n  {.[i_keep,]} # Apply i_keep matrix here to retain non-outlying participants\n\n# Grep rs column numbers to create the geno_string file required for mvBIMBAM format\nrs_cols &lt;- grep(\"^rs\", colnames(df_synth), value = TRUE)\n\n# Create geno_string format required for mvBIMBAM, filtering data set for only i_keep participants\nGeno_String &lt;- map(rs_cols, ~ {\n  Geno_write &lt;- df_synth %&gt;%\n    select(all_of(.x), all_of(traits)) %&gt;%\n    filter(complete.cases(.)) %&gt;%\n    select(all_of(.x))%&gt;%\n    {.[i_keep,]}\n  \n  # Creating the Geno_String for each SNP rsID  \n  Geno_String &lt;- paste0(unlist(c(Geno_write)), collapse = \",\")\n  Geno_String &lt;- paste0(.x, \",\", Geno_String)\n  \n  Geno_String\n}) \n\n# Polish geno_string for mvBIMBAM\nfinal_Geno_String &lt;- paste0(unlist(Geno_String), collapse = \"\\n\")\nM &lt;- length(unlist(strsplit(Geno_String[[1]], \",\"))) - 1\nN &lt;- length(Geno_String)\nfinal_Geno_String &lt;- paste0(M, \"\\n\", N, \"\\n\", final_Geno_String)\n\n# Write it out \nwriteLines(final_Geno_String, con = \"./inputs/geno_bimbam.txt\", sep = \"\") ###CUSTOMIZE** (optional, file name)\n\n\n\n2.3.9.3 bnlearn\n\n# Curate bnlearn data (convert AA/BB coding back to additive) \nGeno_write2 &lt;- Geno_write %&gt;%\n    mutate_at(\n    .vars = vars(starts_with(\"rs\")),\n    .funs = list(~ case_when(\n      . ==  \"BB\" ~ 2,\n      . == \"AB\" ~ 1,\n      . ==  \"AA\" ~ 0\n    ))\n  )\n\n# Create merged data frame\nbnlearn_data &lt;- data.frame(Geno_write2, round(qn_resid_Y[i_keep,], 8))\n\n# The package to learn the Bayesian networks (bnlearn) does not support integer data,\n# so convert integer columns to numeric\nbnlearn_data[sapply(bnlearn_data, class) == \"integer\"] &lt;- \n  sapply(bnlearn_data[sapply(bnlearn_data, class) == \"integer\"], as.numeric)\n\n# Write data for bnlearn\nsaveRDS(bnlearn_data, file = \"data/QuantNorm.rds\") ###CUSTOMIZE** (optional, file name)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Overview\nThis guide will focus on the application of two multivariate Bayesian software programs: (1) bnlearn and (2) mvBIMBAM.\nApproach 1: bnlearn - bnlearn is an R package for learning the graphical structure of Bayesian networks,estimating their parameters, and performing some useful inference as described in:\nScutari M, Howell P, Balding DJ, Mackay I. Multiple Quantitative Trait Analysis Using Bayesian Networks. Genetics. 2014 Apr 11;198(1):129–137. PMID: 25236454 PMCID: PMC4174925 DOI: https://doi.org/10.1534/genetics.114.165704\nand at:\nwww.bnlearn.com\nAdditional details about the method and its interpretation can be found in the bnlearn chapter of this book (or 01_mvNUR_bnlearn.Rmd in the GitHub repository).\nApproach 2: mvBIMBAM - mvBIMBAM implements a terminal-based Bayesian approach for genetic association analysis of multiple related phenotypes, as described in:\nShim H, Chasman DI, Smith JD, Mora S, Ridker PM, Nickerson DA, Krauss RM, Stephens M. A multivariate genome-wide association analysis of 10 LDL subfractions, and their response to statin treatment, in 1868 Caucasians. PLoS One. 2015 Apr 21;10(4):e0120758. doi: https://doi.org/10.1371/journal.pone.0120758. PMID: 25898129; PMCID: PMC4405269.\nStephens M. A unified framework for association analysis with multiple related phenotypes. PLoS One. 2013 Jul 5;8(7):e65245. doi: https://doi.org/10.1371/journal.pone.0065245. Erratum in: PLoS One. 2019 Mar 19;14(3):e0213951. PMID: 23861737; PMCID: PMC3702528.\nAdditional details about the method and its interpretation can be found in the mvBIMBAM chapter of this book (or in 02_mvNUR_mvBIMBAM.Rmd in the GitHub repository).\nThroughout all markdowns, we have flagged lines that will need to be modified by the user if adapting this code for your own data using ###CUSTOMIZE** annotation.\nAlso note that while bnlearn is run directly in R, mvBIMBAM is a terminal-based program with no point/click desktop app. As such, please note that this example code, particularly the mvBIMBAM approach, requires at least an introductory understanding of R and Unix. Some great introductory R/Unix resources are listed at the end of this document.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#overview",
    "href": "intro.html#overview",
    "title": "1  Introduction",
    "section": "1.2 Overview",
    "text": "1.2 Overview\nI have a Bayesian inference joke but the first three people I told it to didn’t laugh and now I’m not so sure it’s funny. - (JSEllenberg?)\nThis repository was created to support a presentation at the International Society of Nurses in Genetics:\nHeinsberg LW. Multivariate Bayesian Approaches for Analyzing Correlated Phenotypes in Nursing Research. (Expert Lecturer Abstract, Podium). Presented at the International Society of Nurses in Genetics, November 2023, Providence, Rhode Island.\nwhich has been adapted for (hopeful) publication as a manuscript entitled:\nHeinsberg LW, Davis TS, Maher D, Bender CM, Conley YP, Weeks DE. A Guide to Multivariate Bayesian Analyses in Nursing Research. In preparation for submission to Biological Research for Nursing.\nThe goal of this repository is to provide detailed code and a fully synthetic example data set to guide nurse scientists and other researchers in conducting multivariate Bayesian analyses to examine associations between correlated phenotypes and single nucleotide polymorphisms (SNPs, i.e., genetic variants). This guide will focus on the application of two multivariate Bayesian software programs: (1) bnlearn and (2) mvBIMBAM.\nApproach 1: bnlearn - bnlearn is an R package for learning the graphical structure of Bayesian networks,estimating their parameters, and performing some useful inference as described in:\nScutari M, Howell P, Balding DJ, Mackay I. Multiple Quantitative Trait Analysis Using Bayesian Networks. Genetics. 2014 Apr 11;198(1):129–137. PMID: 25236454 PMCID: PMC4174925 DOI: https://doi.org/10.1534/genetics.114.165704\nand at:\nwww.bnlearn.com\nAdditional details about the method and its interpretation can be found in 01_mvNUR_bnlearn.Rmd.\nApproach 2: mvBIMBAM - mvBIMBAM implements a terminal-based Bayesian approach for genetic association analysis of multiple related phenotypes, as described in:\nShim H, Chasman DI, Smith JD, Mora S, Ridker PM, Nickerson DA, Krauss RM, Stephens M. A multivariate genome-wide association analysis of 10 LDL subfractions, and their response to statin treatment, in 1868 Caucasians. PLoS One. 2015 Apr 21;10(4):e0120758. doi: https://doi.org/10.1371/journal.pone.0120758. PMID: 25898129; PMCID: PMC4405269.\nStephens M. A unified framework for association analysis with multiple related phenotypes. PLoS One. 2013 Jul 5;8(7):e65245. doi: https://doi.org/10.1371/journal.pone.0065245. Erratum in: PLoS One. 2019 Mar 19;14(3):e0213951. PMID: 23861737; PMCID: PMC3702528.\nAdditional details about the method and its interpretation can be found in 02_mvNUR_mvBIMBAM.Rmd.\nThroughout all markdowns, we have flagged lines that will need to be modified by the user if adapting this code for your own data using ###CUSTOMIZE** annotation.\nAlso note that while bnlearn is run directly in R, mvBIMBAM is a terminal-based program with no point/click desktop app. As such, please note that this example code, particularly the mvBIMBAM approach, requires at least an introductory understanding of R and Unix. Some great introductory R/Unix resources are listed at the end of this document.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#installation",
    "href": "intro.html#installation",
    "title": "1  Introduction",
    "section": "1.2 Installation",
    "text": "1.2 Installation\n\n1.2.1 bnlearn\nYou can install bnlearn from CRAN using:\ninstall.packages(\"bnlearn\")\nor\ninstall.packages(\"https://www.bnlearn.com/releases/bnlearn_latest.tar.gz\", repos = NULL, type = \"source\")\nCheck your R version if you are having any issues installing. As of October 2023, bnlearn requires R version 4.2.0 or higher.\n\n\n1.2.2 mvBIMBAM\nmvBIMBAM is designed to be installed from GitHub. The binary executable file for Linux is in the https://github.com/heejungshim/mvBIMBAM/bin/ directory while a zip file of the binary executable file, source code, and example input files for Mac is in https://github.com/heejungshim/mvBIMBAM/forMAC directory. NOTE: The software executable is called ‘bimbam’, but we refer to the program as ‘mvBIMBAM’ throughout.\nHOWEVER, when developing/testing this tutorial, several of us ran into installation issues for Mac. Ultimately, we had to modify the program’s makefile to support installation. We have alerted the mvBIMABM software maintainer of this issue, but have not seen it resolved. As such, we provide a modified Mac download to make this process easier for users of this tutorial (allowable under GNU General Public License (GPLv3+)).\nTo install mvBIMBAM, please follow the instructions below, which were written with the assumption that users have an introductory understanding of navigating your computer using the terminal/Unix commands. If you are new to Unix navigation via the terminal, please visit this link for a brief introduction.\n\n1.2.2.1 Mac\n\nDownload BIMBAM_multi_pheno_MAC_M1_modified.zip or BIMBAM_multi_pheno_MAC_Intel_modified.zip from our GitHub repository. The former is for newer Apple silicon/M1 macs and the latter is for older macs. If you are not sure which Mac you have, you can click on the apple symbol in the upper left corner of your machine. If you have an Apple silicon, the Chip will be listed as Apple M1 or M2. If you have the Apple Intel, you will see the processor listed as Intel Core i5, i7, or similar.\nUnzip the file by double clicking the zipped folder.\nUsing the terminal, navigate to the newly unzipped mvBIMBAM folder\n\ncd Desktop/BIMBAM_multi_pheno_MAC_M1_modified\npwd \nor\ncd Desktop/BIMBAM_multi_pheno_MAC_Intel_modified\npwd \nFor example, on my machine, when I use the pwd command (print working directory), my folder is located at: /Users/username/Desktop/BIMBAM_multi_pheno_MAC\n\nRun make clean and make all terminal commands which will activate the software build automation tool to compile the C++ source code into an executable bimbam program.\n\nmake clean\nmake all\nNote that there is, unfortunately, no obvious sign that install was successful. Installation can be confirmed in step 5.\n\nMove the executable file to system’s PATH environment variable, such as /usr/local/bin, so the program can be called from any location (vs. only the folder where the executable file resides). To do this, navigate to the location of the Unix executable file via the terminal and then use the move (mv) command.\n\nsudo mv bimbam /usr/local/bin/\nConfirm that the install/move worked via this command:\nwhich bimbam\nFor example, on my machine, bimbam is located at /usr/local/bin/bimbam now.\nNow if you type\nbimbam\nat the Unix prompt and hit return, it should print out this message:\n BIMBAM version 0.99a, visit http://stephenslab.uchicago.edu for possible update.\n Developed by Yongtao Guan ytguan.at.gmail.com, all rights to be lefted to GNU GPL.\n References: Guan and Stephens (2008), Servin and Stephens (2007), Scheet and Stephens (2006).\n Updated March 14 2009.\n\n1.2.2.1.1 Modification details\nIf you are interested in more details related to the installation issue, and how we modified the makefile to correct this issue, please see our installation hack page of this book or Installation Appendix of the GitHub repository.\n\n\n1.2.2.1.2 Troubleshooting\nNote that you need to have GSL (GNU Scientific Library) installed on your machine before you can install mvBIMBAM. GSL is an open-source software library that provides a wide range of mathematical and statistical functions for scientific and numerical computing. Please see our troubleshooting page of this book or Installation Appendix of the GitHub repository for tips on getting GSL installed on your machine.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#synthetic-data-set-overview",
    "href": "intro.html#synthetic-data-set-overview",
    "title": "1  Introduction",
    "section": "1.3 Synthetic data set overview",
    "text": "1.3 Synthetic data set overview\nTo facilitate hands-on learning, a synthetic data set was created for use with this example code. The synthetic data set was created from a study of women with breast cancer (BrCa). This data set contains no real data, but mimics the correlation structure of the true data set. The original data set contained data for 110 participants and included data for 6 symptoms, 3 demographic variables, and 6 SNPs. We created a synthetic version of this data set with fake data for 770 participants for use in this tutorial.\nData set name: BrCa_synthetic.csv (see GitHub repository for details).\nVariable descriptions:\nSymptoms/Outcomes\n-ID: Participant ID\n-EMO_tscore: Anxiety (PROMIS Anxiety T Score)\n-bdito: Depression (Beck’s Depression Inventory)\n-FAT_tscore: Fatigue (PROMIS Fatigue Score)\n-paohcif: Cognitive Function (Patient’s Assessment of Own Functioning Inventory - Cognitive Function)\n-EPSscore: Sleepiness (Epworth Daytime Sleepiness)\n-worst_pain: Pain (Self-reported numeric rating of “average pain”)\nDemographics/Covariates\n-age: Age in years\n-education: Education in years\n-race: Race (Self-identified, 0=White, 1=Black)\nSNPs/Predictors\n-rs #s (SNPs)\n\n# Read in a mapping of variable name to informative label\ndict &lt;- read.csv(\"data/BrCa_synthetic_SimpleDict.csv\")\npander::pander(dict, \"Data dictionary\") \n\n\nData dictionary (continued below)\n\n\n\n\n\n\n\nVariable\nLabel\nDescription\n\n\n\n\nEmo_tscore\nAnxiety\nPROMIS Emotional Distress Anxiety (Short Form 8a) - 8 items measuring emotional distress and anxiety (panic, fearfulness, worry, dread, tension,nervousness, restlessness, and somatic symptoms including racing heart and dizziness) in the last 7 days. This instrument generates T-scores, which are standard scores with a mean of 50 and standard deviation of 10 in the U.S. general population. Higher T-scores indicate worse distress and anxiety. T-scores range from 10 to 90.\n\n\nbdito\nDepression\nThe Beck Depression Inventory-II - 21-items measuring severity of depression (i.e., grief, loss, flat affect, withdrawal, mania) over a two-week period. Scores range from 0 to 63, where high scores indicate higher levels or more severe depression.\n\n\nFAT_tscore\nFatigue\nPROMIS Fatigue (Short Form 8a) - 8 items measuring the experience of fatigue and the interference of fatigue on daily activities over the past 7 days. This instrument generates T-scores, which are standard scores with a mean of 50 and standard deviation of 10 in the U.S. general population. Higher T-scores indicate worse fatigue. T-scores range from 10 to 90.\n\n\npaohcif\nCognitive function\nPatient assessment of own cognitive functioning - 33 items measuring self-reported ‘recent’ cognitive function consisting of 5 dimensions: memory, language and communication, use of hands, sensory-perceptual, higher level cognitive and intellectual functioning. Higher scores indicate worse perceived cognitive functioning. Scores range from 0 to 155.\n\n\nEPSscore\nSleepiness\nEpworth Sleepiness Scale - 8 item scale measuring self-reported ‘recent’ daytime sleepiness. Higher score indicate greater daytime sleepiness. Scores range from 0 to 24.\n\n\npain\nPain\nBrief Pain Inventory (Short Form) - 9 items a widely used clinical tool for assessing pain (worst pain in the last 24 hours [0-10], least pain in the last 24 hours [0-10], pain on average [0-10], paing at the time of the interview [0-10], pain relief from treatment(s) in the last 24 hours [0%-100%]). Higher scores indicate higher levels of pain, each item ranges from 0-10.\n\n\nrs4880\nVariant 1\nSOD2 gene, hg19 postion chr6: 160113872\n\n\nrs5746136\nVariant 2\nSOD2 gene, hg19 postiion chr6: 160103084\n\n\nrs1041740\nVariant 3\nSOD1 gene, hg19 postiion chr21: 33040162\n\n\nrs10432782\nVariant 4\nSOD1 gene, hg19 postiion chr21: 33036391\n\n\nrs4135225\nVariant 5\nTXN gene, hg19 postiion chr9: 113006691\n\n\nrs7522705\nVariant 6\nPRDX1 gene, hg19 postiion chr1: 45992300\n\n\nrace\nRace\nSelf-identified race, 0=White, 1=Black\n\n\nage\nAge\nAge in years\n\n\neducation\nEducation\nSelf-reported years of education\n\n\n\n\n\n\n\n\n\n\nType\nCitation\n\n\n\n\nNumeric\nPilkonis, P.A. et al. (2011) Item banks for measureing emotional distress from the patient-reported outcomes measurement information system (PROMIS): Depression, Anxiety, and Anger, Assesssment, 18(3), 263-283\n\n\nNumeric\nBeck, A.T. et al. (1996) Beck Depression Inventory-II. San Antonio: The Psychological Corporation\n\n\nNumeric\nCell, D. et al. (2016) PROMIS fatigue item bank had clinical validity across diverse chronic conditions. Journal of Clinical Epidemiology, 73, 128-134\n\n\nNumeric\nChelune, G. J. et al. (1986) Neuropsychological and personality correlates of patients’ complaints of disability. Advances in clinical Neuropsychology, 1986:95-126\n\n\nNumeric\nJohns MW. A new method for measuring daytime sleepiness: The Epworth Sleepiness Scale. Sleep 1991; 14(6):540-5\n\n\nNumeric\nCleeland, C.S. et al. (2009). Pain assessment: Global use of the Brief Pain Inventory. Annals, Academy of Medicine, Sigapore, 23(2), 129-138.\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric, encoded value\n\n\n\nNumeric\n\n\n\nNumeric",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#examples",
    "href": "intro.html#examples",
    "title": "1  Introduction",
    "section": "1.4 Examples",
    "text": "1.4 Examples\nTo prepare the data before running the examples, see our data prep chapter followed by our bnlearn and mvBIMBAM chapters. Note that .Rmd versions of all files are available in our GitHub repository.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#runix-basics",
    "href": "intro.html#runix-basics",
    "title": "1  Introduction",
    "section": "1.5 R/Unix basics",
    "text": "1.5 R/Unix basics\n\nhttps://danieleweeks.github.io/HuGen2071/preparation.html\nhttps://github.com/ajwills72/rminr\nhttps://www.andywills.info/rminr/#beginners\nhttps://www.youtube.com/watch?v=IrDUcdpPmdI",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#power-calculation-resources",
    "href": "intro.html#power-calculation-resources",
    "title": "1  Introduction",
    "section": "1.6 Power calculation resources",
    "text": "1.6 Power calculation resources\n\nhttps://www.andywills.info/rminr/power-bayesian.html",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#contact-information",
    "href": "intro.html#contact-information",
    "title": "1  Introduction",
    "section": "1.7 Contact information",
    "text": "1.7 Contact information\nIf you have any questions or comments, please feel free to contact me!\nLacey W. Heinsberg, PhD, RN: law145@pitt.edu",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#acknowledgments",
    "href": "intro.html#acknowledgments",
    "title": "1  Introduction",
    "section": "1.8 Acknowledgments",
    "text": "1.8 Acknowledgments\nI’d like to express my gratitude to the following for their support and contributions to this repository:\n\nSupport from the National Institutes of Health under award number K99HD107030 made this project possible, and for that, I’m truly grateful.\nSpecial thanks to Dr. Tara Davis and Mr. Dylan Maher for being “test users” and providing their invaluable feedback on this guide.\nMy deepest gratitude to Dr. Daniel Weeks for … everything. If it weren’t for his guidance and inspiration, I would never have ventured into the mystifying world of Bayesian statistics.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "bnlearn.html",
    "href": "bnlearn.html",
    "title": "3  bnlearn",
    "section": "",
    "text": "3.1 Overview\nThis code was adapted from previous work led by Jerry Zhang, Lacey Heinsberg, and Daniel Weeks:\nZhang JZ, Heinsberg LW, Krishnan M, Hawley NL, Major TJ, Carlson JC, Harré Hindmarsh J, Watson H, Qasim M, Stamp LK, Dalbeth N, Murphy R, Sun G, Cheng H, Naseri T, Reupena MS, Kershaw EE, Deka R, McGarvey ST, Minster RL, Merriman TR, Weeks DE. Multivariate analysis of a missense variant in CREBRF reveals associations with measures of adiposity in people of Polynesian ancestries. Genet Epidemiol. 2023 Feb;47(1):105-118. doi: https://doi.org/10.1002/gepi.22508. PMID: 36352773; PMCID: PMC9892232.\nGitHub Repository\nwhich was created/adapted from:\nScutari M, Howell P, Balding DJ, Mackay I. Multiple Quantitative Trait Analysis Using Bayesian Networks. Genetics. Genetics; 2014 Apr 11;198(1):129–137. PMID: 25236454 PMCID: PMC4174925 DOI: https://doi.org/10.1534/genetics.114.165704\nNOTE: Some of the functions were copied from the bnlearn example at Link as allowed under the Creative Commons Attribution-Share Alike License.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>bnlearn</span>"
    ]
  },
  {
    "objectID": "bnlearn.html#overview",
    "href": "bnlearn.html#overview",
    "title": "3  bnlearn",
    "section": "",
    "text": "3.1.1 bnlearn\nThe R package bnlearn is helpful for learning the graphical structure of Bayesian networks, estimating their parameters, and performing some useful inference. Installation instructions can be found in the README file.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>bnlearn</span>"
    ]
  },
  {
    "objectID": "bnlearn.html#load-libraries",
    "href": "bnlearn.html#load-libraries",
    "title": "3  bnlearn",
    "section": "3.2 Load Libraries",
    "text": "3.2 Load Libraries\n\nlibrary(tidyverse) \nlibrary(lme4)      \nlibrary(bnlearn)  \nlibrary(parallel)  \n# The 'graph' package is a Bioconductor package\n# One of our tutorial test users had trouble installing graph and Rgraphviz packages and had to force install as shown below\n#if (!require(\"BiocManager\", quietly = TRUE))\n#    install.packages(\"BiocManager\")\n#BiocManager::install(\"graph\", force = TRUE)\nlibrary(graph)     \nlibrary(pander)   \nlibrary(ggnetwork)\n# The 'Rgraphviz' is a Bioconductor packaage\n#if (!require(\"BiocManager\", quietly = TRUE))\n#    install.packages(\"BiocManager\")\n#BiocManager::install(\"Rgraphviz\", force = TRUE)\nlibrary(Rgraphviz)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>bnlearn</span>"
    ]
  },
  {
    "objectID": "bnlearn.html#read-in-the-synthetic-dataset",
    "href": "bnlearn.html#read-in-the-synthetic-dataset",
    "title": "3  bnlearn",
    "section": "3.3 Read in the synthetic dataset",
    "text": "3.3 Read in the synthetic dataset\nAs detailed in created in the data preparation section, the synthetic phenotype data created for this example were adjusted for age and sex, quantile normalized, and outliers were removed. The quantile normalized adjusted data set is read in below. Please see the introduction section for more details about the data set and variables.\n\ndf &lt;- readRDS(\"data/QuantNorm.rds\") ###CUSTOMIZE** (if input file name was changed in 00_ workflow)\n\nRead in traits/gene names created there as well.\n\nload(\"./data/TraitsGenes.RData\") ###CUSTOMIZE** (if input file name was changed in 00_ workflow)\n\nAlternatively, store this information manually as shown below.\n# Define the phenotypes of interest\ntraits &lt;- c(\"EMO_tscore\", \"bdito\", \"FAT_tscore\", \"paohcif\", \"EPSscore\", \"pain\") ###CUSTOMIZE**\ntrait_mapping &lt;- c(\"Anxiety\", \"Depression\", \"Fatigue\", \"Cognitive function\", \"Sleepiness\", \"Pain\") ###CUSTOMIZE**\ncustom_labels &lt;- setNames(trait_mapping, traits)\n# Create expanded custom labels \ncustom_labels2 &lt;- c(custom_labels, setNames(genes, genes))\n\n# Define variants of interest \ngenes &lt;- c(\"rs4880\", \"rs5746136\", \"rs1041740\", \"rs10432782\", \"rs4135225\", \"rs7522705\") ###CUSTOMIZE**",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>bnlearn</span>"
    ]
  },
  {
    "objectID": "bnlearn.html#bayesian-network-estimation",
    "href": "bnlearn.html#bayesian-network-estimation",
    "title": "3  bnlearn",
    "section": "3.4 Bayesian Network estimation",
    "text": "3.4 Bayesian Network estimation\n\n3.4.1 Load functions\nFor simplicity, all bnlearn analysis and plotting functions are stored in see bnlearn_functions.R in the GitHub repository. See that file for details.\n\nsource(\"./bnlearn_functions.R\")\n\n\n\n3.4.2 Apply functions and visualize results\n\n3.4.2.1 Data summaries\n\n# Check dimensions of the synthetic data used here \ndim(df)\n\n[1] 763  12\n\n# Summary of data\nsummary(df)\n\n     rs4880         rs5746136        rs1041740        rs10432782    \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.9725   Mean   :0.4404   Mean   :0.4312   Mean   :0.3028  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :2.0000   Max.   :2.0000   Max.   :2.0000   Max.   :2.0000  \n   rs4135225        rs7522705        EMO_tscore            bdito          \n Min.   :0.0000   Min.   :0.0000   Min.   :-8.598853   Min.   :-8.142873  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:-4.745668   1st Qu.:-4.745668  \n Median :1.0000   Median :1.0000   Median :-1.117270   Median :-1.117270  \n Mean   :0.6606   Mean   :0.7339   Mean   :-0.000116   Mean   : 0.001758  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.: 3.607629   3rd Qu.: 3.607629  \n Max.   :2.0000   Max.   :2.0000   Max.   :16.803582   Max.   :17.664804  \n   FAT_tscore           paohcif             EPSscore        \n Min.   :-8.598853   Min.   :-8.598853   Min.   :-8.598853  \n 1st Qu.:-4.802835   1st Qu.:-4.802835   1st Qu.:-4.876630  \n Median :-1.117270   Median :-1.117270   Median :-0.885189  \n Mean   :-0.000098   Mean   :-0.001958   Mean   : 0.000935  \n 3rd Qu.: 3.607629   3rd Qu.: 3.607629   3rd Qu.: 3.607629  \n Max.   :17.664804   Max.   :17.664804   Max.   :17.664804  \n      pain          \n Min.   :-8.370863  \n 1st Qu.:-4.802835  \n Median :-1.278710  \n Mean   :-0.003648  \n 3rd Qu.: 3.468126  \n Max.   :17.664804  \n\n# Correlation structure of data\ncor(df[,traits])\n\n           EMO_tscore     bdito FAT_tscore   paohcif  EPSscore      pain\nEMO_tscore  1.0000000 0.5990665  0.6372831 0.5440664 0.1828286 0.2252510\nbdito       0.5990665 1.0000000  0.4163014 0.5059705 0.1838254 0.2103236\nFAT_tscore  0.6372831 0.4163014  1.0000000 0.5600751 0.3750783 0.3998224\npaohcif     0.5440664 0.5059705  0.5600751 1.0000000 0.1374550 0.2780501\nEPSscore    0.1828286 0.1838254  0.3750783 0.1374550 1.0000000 0.4317377\npain        0.2252510 0.2103236  0.3998224 0.2780501 0.4317377 1.0000000\n\n# View list of traits/SNPs of interest\ntraits\n\n[1] \"EMO_tscore\" \"bdito\"      \"FAT_tscore\" \"paohcif\"    \"EPSscore\"  \n[6] \"pain\"      \n\ngenes\n\n[1] \"rs4880\"     \"rs5746136\"  \"rs1041740\"  \"rs10432782\" \"rs4135225\" \n[6] \"rs7522705\" \n\n\n\n\n3.4.2.2 Regular graph\nThe run_plot_graph function calls the fit.the.model() and xval.the.model() functions to learn and visualize the Bayesian networks in the data. This function also customizes node labels and appearance, and then returns results related to the network analysis. Note that the following function uses parallel computing which involves breaking down a complex task into smaller subtasks that can be executed simultaneously, or in parallel, by multiple processors or computers to speed up computationally intense calculations.\nThe fit.the.model() function constructs the Bayesian network model by employing a constrained learning algorithm based on conditional independence testing, specifically the semi-interleaved HITON-PC method. In this process, the algorithm identifies “parent-child” relationships within the network, where nodes represent either phenotypic traits or genetic variants, and edges signify associations between these nodes. Notably, traits can have parent nodes that are either genetic variants or other traits, but they can only serve as parents to other traits, adhering to the constraint that genetic variants do not act on traits (since genotypes are constant across an individual’s lifespan).\nTo enforce this constraint, a “blacklist” is created using the tiers2blacklist() function, preventing arcs from being directed towards specific nodes. This restriction aims to guide the learning process by ensuring that known causal relationships are inferred in the correct direction from genetic variants to traits, while also allowing for customization to blacklist other traits if needed (e.g., you can customize this to force/restrict a trait-&gt;trait relationship).\nAfter the networks are learned, the nodes are categorized into subsets for visualization, and the network structures are determined by maximizing the Bayesian Information Criteria (BIC). This approach facilitates the construction of Bayesian networks that capture probabilistic relationships between traits and genetic variants, with the learned structures reflecting potential causal associations.\nFurther details on the methodology can be found at http://www.bnlearn.com/research/genetics14/.\nThe xval.the.model() function performs model training with n-fold cross-validation (in the case of this example, 5-fold cross-validation).\nDuring this process, the data set is divided into multiple partitions, with each partition serving as the test set while the remaining data is used for training. This process is repeated iteratively to ensure that all data points are included in the test set at least once.\nDuring each fold of cross-validation, the following steps are performed:\n\nData Splitting: The dataset is divided into a training set (dtraining) and a test set (dtest).\nModel Fitting: A Bayesian network model is fitted to the training data using the fit.the.model() function. This model captures the probabilistic relationships between phenotypic traits and genetic variants.\nPrediction: The model is used to predict the values of phenotypic traits on the test set. These predictions are stored in the prediction matrix.\nPosterior Estimation: Posterior estimates are computed for each trait based on the test data. These estimates are stored in the post matrix.\nCorrelation Computation: The correlations between the predicted and observed values for each trait are calculated, both before (predcor) and after (postcor) cross-validation. These correlations provide a measure of the model’s predictive performance.\nRidge Regression (Optional): If the ridge parameter is set to true, ridge regression is applied to certain nodes of the Bayesian network model to improve model performance.\n\nFinally, the function returns various results, including the predicted values, posterior estimates, observed values, and correlation coefficients for each trait. Additionally, it provides the learned models for each fold of cross-validation. This process allows for the assessment of how well the Bayesian network model generalizes to unseen data and provides insights into its predictive capabilities.\nHere, we will call the above functions and plot the base graph showing only the directions of association but not the strengths.\n\nset.seed(6)\nresults &lt;- run_plot_graph(data = df, k_crossval = 5, k_iterations = 5, alpha = 0.1, ncluster = 8, custom_labels = custom_labels2) \n\n* overall cross-validated correlations:\n  &gt; PREDCOR( EMO_tscore ): 0.3450264 \n  &gt; POSTCOR( EMO_tscore ): 0.344612 \n  &gt; PREDCOR( bdito ): 0.5794972 \n  &gt; POSTCOR( bdito ): 0.1615845 \n  &gt; PREDCOR( FAT_tscore ): 0.7323366 \n  &gt; POSTCOR( FAT_tscore ): 0.4705999 \n  &gt; PREDCOR( paohcif ): 0.6703178 \n  &gt; POSTCOR( paohcif ): 0.3106302 \n  &gt; PREDCOR( EPSscore ): 0.4307685 \n  &gt; POSTCOR( EPSscore ): 0.2847392 \n  &gt; PREDCOR( pain ): 0.5086095 \n  &gt; POSTCOR( pain ): 0.3503363 \n* overall cross-validated correlations:\n  &gt; PREDCOR( EMO_tscore ): 0.3668206 \n  &gt; POSTCOR( EMO_tscore ): 0.3636677 \n  &gt; PREDCOR( bdito ): 0.5824107 \n  &gt; POSTCOR( bdito ): 0.1738666 \n  &gt; PREDCOR( FAT_tscore ): 0.7340804 \n  &gt; POSTCOR( FAT_tscore ): 0.4747315 \n  &gt; PREDCOR( paohcif ): 0.6728188 \n  &gt; POSTCOR( paohcif ): 0.3143167 \n  &gt; PREDCOR( EPSscore ): 0.4332637 \n  &gt; POSTCOR( EPSscore ): 0.2803622 \n  &gt; PREDCOR( pain ): 0.516585 \n  &gt; POSTCOR( pain ): 0.3449039 \n* overall cross-validated correlations:\n  &gt; PREDCOR( EMO_tscore ): 0.3362601 \n  &gt; POSTCOR( EMO_tscore ): 0.3344038 \n  &gt; PREDCOR( bdito ): 0.6035443 \n  &gt; POSTCOR( bdito ): 0.1921227 \n  &gt; PREDCOR( FAT_tscore ): 0.7327031 \n  &gt; POSTCOR( FAT_tscore ): 0.4638167 \n  &gt; PREDCOR( paohcif ): 0.6564999 \n  &gt; POSTCOR( paohcif ): 0.3199182 \n  &gt; PREDCOR( EPSscore ): 0.4288491 \n  &gt; POSTCOR( EPSscore ): 0.2863203 \n  &gt; PREDCOR( pain ): 0.5386219 \n  &gt; POSTCOR( pain ): 0.3475677 \n* overall cross-validated correlations:\n  &gt; PREDCOR( EMO_tscore ): 0.3339423 \n  &gt; POSTCOR( EMO_tscore ): 0.3316114 \n  &gt; PREDCOR( bdito ): 0.5858688 \n  &gt; POSTCOR( bdito ): 0.1608937 \n  &gt; PREDCOR( FAT_tscore ): 0.7323323 \n  &gt; POSTCOR( FAT_tscore ): 0.4716136 \n  &gt; PREDCOR( paohcif ): 0.674619 \n  &gt; POSTCOR( paohcif ): 0.3213664 \n  &gt; PREDCOR( EPSscore ): 0.4576816 \n  &gt; POSTCOR( EPSscore ): 0.2915639 \n  &gt; PREDCOR( pain ): 0.5089625 \n  &gt; POSTCOR( pain ): 0.3568388 \n* overall cross-validated correlations:\n  &gt; PREDCOR( EMO_tscore ): 0.3341934 \n  &gt; POSTCOR( EMO_tscore ): 0.3332159 \n  &gt; PREDCOR( bdito ): 0.590734 \n  &gt; POSTCOR( bdito ): 0.1402795 \n  &gt; PREDCOR( FAT_tscore ): 0.7350113 \n  &gt; POSTCOR( FAT_tscore ): 0.4741796 \n  &gt; PREDCOR( paohcif ): 0.670765 \n  &gt; POSTCOR( paohcif ): 0.31503 \n  &gt; PREDCOR( EPSscore ): 0.4389516 \n  &gt; POSTCOR( EPSscore ): 0.27923 \n  &gt; PREDCOR( pain ): 0.5230457 \n  &gt; POSTCOR( pain ): 0.3422386 \nEMO_tscore      bdito FAT_tscore    paohcif   EPSscore       pain \n 0.3432486  0.5884110  0.7332928  0.6690041  0.4379029  0.5191649 \nEMO_tscore      bdito FAT_tscore    paohcif   EPSscore       pain \n 0.3415022  0.1657494  0.4709883  0.3162523  0.2844431  0.3483771 \nthreshold:  0.6 \nmin strength &gt; threshold:  0.76 \nstrength:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.04 0.04 0.08 0.08 0.08 0.08 0.12 0.12 0.12 0.12 0.12 0.12 0.16 0.16 0.2 0.2 0.32 0.32 0.36 0.36 0.4 0.4 0.6 0.6 0.76 0.76 0.76 0.76 0.76 0.76 0.76 0.76 0.8 0.8 0.84 0.84 0.88 0.88 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\n\n\n\n\n\n\n\n\n\n3.4.2.3 Labeled high-strength graph\nHere we redraw the graph adding strengths/directions to the association lines.\nThe strength and directionalities of the edges of the Bayesian networks are inferred through an iterative process so resulting networks vary a bit from run to run. As such, representative networks (i.e., averaged) are plotted.\nThe code below calls in the function created above to add specific details on the strength (Es) and direction (Ed) of each edge that summarize the results across the total number of iterations.\nEdge strength is a measure of confidence of that edge while fixing the rest of the network structure and is defined as the empirical frequency a specific edge is observed over a set of networks learned from iterations (i.e., the number of times the edge was present out of the total number of iterations).\nEdge direction represents the probability of the edge’s direction conditional on the edge’s presence within the network (i.e., the number of times the edge traveled in a specific direction out of the total number of iterations in which it was present).\nAn edge is included in the network graph if its strength is larger than a significance threshold learned from the iterative samples.\n\n# Redraw graph adding strengths/directions to association lines using function created above \n# Here, we use a threshold of 0.9 to indicate \"strong\" associations\n# In this case, edges with a strength &gt;0.9 will be solid, while edges with a strength &lt;0.9 will be dashed\nset.seed(6)\nredraw.graph.labels(\n  results$averaged2,\n  results$strength2,\n  results$averaged,\n  results$traits,\n  custom.threshold = 0.90\n)\n\n\n\n\n\n\n\n\nHere we can visualize the strengths and directions as a table.\n\n# Visualize strengths/directions as a table \nresults$strength2 %&gt;%\n filter(strength &gt; 0 & direction &gt; 0 & strength &gt; results$threshold) %&gt;%\n  arrange(strength) %&gt;% pander()\n\n\n\n\n\n\n\n\n\n\nfrom\nto\nstrength\ndirection\n\n\n\n\nrs1041740\nrs10432782\n0.76\n1\n\n\nrs5746136\nCognitive function\n0.76\n1\n\n\nrs10432782\nAnxiety\n0.76\n1\n\n\nrs10432782\nCognitive function\n0.76\n1\n\n\nFatigue\nPain\n0.8\n1\n\n\nAnxiety\nCognitive function\n0.84\n1\n\n\nPain\nCognitive function\n0.88\n0.09091\n\n\nCognitive function\nPain\n0.88\n0.9091\n\n\nAnxiety\nDepression\n1\n1\n\n\nAnxiety\nFatigue\n1\n1\n\n\nDepression\nCognitive function\n1\n0.96\n\n\nFatigue\nSleepiness\n1\n1\n\n\nFatigue\nCognitive function\n1\n1\n\n\nSleepiness\nPain\n1\n0.84\n\n\nPain\nSleepiness\n1\n0.16\n\n\nrs1041740\nAnxiety\n1\n1\n\n\nrs1041740\nSleepiness\n1\n1\n\n\nrs1041740\nrs4135225\n1\n1\n\n\nrs4135225\nAnxiety\n1\n1\n\n\nrs4135225\nFatigue\n1\n1\n\n\nrs4135225\nPain\n1\n1\n\n\nrs4880\nPain\n1\n1\n\n\nrs4880\nCognitive function\n1\n1\n\n\nrs5746136\nFatigue\n1\n1\n\n\nrs5746136\nSleepiness\n1\n1\n\n\nCognitive function\nDepression\n1\n0.04\n\n\n\n\n\n\n\n3.4.2.4 ggnetwork graph\nFinally, we redraw the graph again. This time, we are changing the colors, line types, and using ggrepel so that node and edge labels do not overlap.\n\n# Redraw graph in black and white using ggnetwork through the function created above \nset.seed(6)\nredraw.label.ggnet(results$averaged2,\n                   results$strength2,\n                   results$averaged,\n                   results$traits, \n                   df_vertex_table = df_vertex_table)\n\n\n\n\n\n\n\n\nInterpretation: Given the complexity of this plot, let’s focus on breaking apart a few results for a single variant, rs5746136. In this example figure, we see direct associations (solid arrows pointing away from the variant) between the rs5746136 with sleepiness and fatigue, and a weaker direct association (dashed line pointing away from the variant) with cognitive function. We also observe an indirect association between rs5746136 and cognitive function through fatigue which can be interpreted as cognitive function being conditionally independent of rs5746136 given the presence of fatigue.\nIn this figure, the strengths (Es) and directions (Ed) of the relationships are also depicted along the edges (Es:Ed). As described above, the strength is a measure of confidence of that edge while fixing the rest of the network structure and is defined as the empirical frequency a specific edge is observed over a set of networks learned from iterations (i.e., the number of times the edge was present out of the total number of iterations). Edge direction represents the probability of the edge’s direction conditional on the edge’s presence within the network (i.e., the number of times the edge traveled in a specific direction out of the total number of iterations in which it was present). So in the example figure, we see an association between rs5746136 and fatigue with Es:Ed values of 1:1. This means that the edge was present in 100% of all iterations and the relationship traveled from the rs5746136 variant (“parent”) to fatigue (“child”) 100% of the time. Note that in our “blacklist” code above, we specified that all variants could only be a “parent” and not a “child” – so directions of 1 facing away from variants to symptoms are expected. This is not the case with the arrow traveling from cognitive function to pain. With Es:Ed values of 0.88:0.91, this relationship was observed in 88% of iterations but traveled in the shown direction in only 91% of realizations. Finally, note that edges with a strength &gt;0.9 are solid, while edges with a strength &lt;0.9 are dashed.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>bnlearn</span>"
    ]
  },
  {
    "objectID": "bnlearn.html#conclusion",
    "href": "bnlearn.html#conclusion",
    "title": "3  bnlearn",
    "section": "3.5 Conclusion",
    "text": "3.5 Conclusion\nAnd with that, we conclude our bnlearn tutorial! We hope that this code is documented in enough detail so that you can easily adapt it for your own projects, but feel free to reach out with any questions! Please see the mvBIMBAM chapter for the mvBIMBAM tutorial!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>bnlearn</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html",
    "href": "mvbimbam.html",
    "title": "4  mvBIMBAM",
    "section": "",
    "text": "4.1 Overview\nPlease note that this code was adapted from previous work led by Jerry Zhang, Lacey Heinsberg, and Daniel Weeks:\nZhang JZ, Heinsberg LW, Krishnan M, Hawley NL, Major TJ, Carlson JC, Harré Hindmarsh J, Watson H, Qasim M, Stamp LK, Dalbeth N, Murphy R, Sun G, Cheng H, Naseri T, Reupena MS, Kershaw EE, Deka R, McGarvey ST, Minster RL, Merriman TR, Weeks DE. Multivariate analysis of a missense variant in CREBRF reveals associations with measures of adiposity in people of Polynesian ancestries. Genet Epidemiol. 2023 Feb;47(1):105-118. doi: 10.1002/gepi.22508. Epub 2022 Nov 9. PMID: 36352773; PMCID: PMC9892232.\nGitHub Repository\nNote this code is dependent upon code from the data preparation section which creates the mvBIMBAM input files detailed below.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html#overview",
    "href": "mvbimbam.html#overview",
    "title": "4  mvBIMBAM",
    "section": "",
    "text": "4.1.1 mvBIMBAM\nmvBIMBAM is a command line program for multivariate genetic association analysis of multiple related phenotypes. In the mvBIMBAM framework, a global null model representing no association between phenotypes and genotypes is compared with an exhaustive combination of alternative models in which all different combinations of phenotype-genotype associations are considered (see mph2 details below). For the alternative models, the mvBIMBAM methodology splits phenotype-genotype associations into all possible partitions of U, D, and I, each representing ‘unassociated’, ‘directly’, and ‘indirectly’ associated. Details about the analyses and interpretation can be found below. Installation and troubleshooting instructions can be found in the README file.\nNOTE: The software executable is called ‘bimbam’, but we refer to the program as ‘mvBIMBAM’ throughout.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html#load-libraries",
    "href": "mvbimbam.html#load-libraries",
    "title": "4  mvBIMBAM",
    "section": "4.2 Load libraries",
    "text": "4.2 Load libraries\nLoad the libraries needed to run the code.\n\nlibrary(tidyverse)\nselect = dplyr::select\nlibrary(ggplot2)\n# The 'preprocessCore' is a Bioconductor package\nlibrary(preprocessCore)\nlibrary(pander)\nlibrary(stringr)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html#data",
    "href": "mvbimbam.html#data",
    "title": "4  mvBIMBAM",
    "section": "4.3 Data",
    "text": "4.3 Data\nMost of our data (created in the data preparation section) are simply called by the system (see below) and not formerly loaded into R. Here though, we will read in our stored lists of phenotypes/variants of interest. See the introduction section for information about phenotypes and SNPs of interest.\n\nload(\"./data/TraitsGenes.RData\") ###CUSTOMIZE** (if input file name was changed in 00_ workflow)\n\nCould also hard code these variables as shown below.\ntraits &lt;- c(\"EMO_tscore\", \"bdito\", \"FAT_tscore\", \"paohcif\", \"EPSscore\", \"pain\") ###CUSTOMIZE**\ntrait_mapping &lt;- c(\"Anxiety\", \"Depression\", \"Fatigue\", \"Cognitive function\", \"Sleepiness\", \"Pain\") ###CUSTOMIZE**\ncustom_labels &lt;- setNames(trait_mapping, traits)\ncustom_labels2 &lt;- c(custom_labels, setNames(genes, genes))\ngenes &lt;- c(\"rs4880\", \"rs5746136\", \"rs1041740\", \"rs10432782\", \"rs4135225\", \"rs7522705\") ###CUSTOMIZE**",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html#mvbimbam-analyses",
    "href": "mvbimbam.html#mvbimbam-analyses",
    "title": "4  mvBIMBAM",
    "section": "4.4 mvBIMBAM analyses",
    "text": "4.4 mvBIMBAM analyses\nWe will now apply mvBIMBAM to the synthetic data set we are working with. Rather than navigating the analyses in the terminal, we can make our code reproducible in R and call mvBIMBAM through the R using call system(). More information about the program can be found under the original mvBIMBAM documentation on GitHub. In brief, the command we need contains the following parameters:\n-g: location of the genotype data (for our example the location is: ./inputs/geno_bimbam.txt) -p: location of the phenotype data (for our example the location is: ./inputs/pheno_bimbam.txt) -o: prefix for output files (for our example we will use: bimbam_out) -f: number of phenotypes to analyze (length(traits), for our example this number is 6) -A: indicate multiple values for sigma (see mvBIMBAM manual for more details; for our example we will use a range of values from 0.05 to 0.4) -mph1 vs. mph2: analysis settings (see mvBIMBMAM manual for more details and our note below; for this example we will run mph2) -r: random seed for reproducibility of results**\n**Random seed: The mvBIMBAM article states: “We maximized the likelihood using an EM algorithm; four independent runs of the algorithm from different starting points produced essentially identical results.” This appears to be implemented in a random way, and so depends on the random number seed. For the purposes of this tutorial, we set a seed number so that the results would be identical each time. In practice, this step is not necessary, so the “-r 5254” section can be deleted from the code below.\nA note about mph1 vs. mph2: In brief, -mph1 performs a simple multivariate test of the null hypothesis vs a general multivariate alternative. Because it does not consider all partitions of the alternative hypothesis, it is quite fast, can handle a moderately large number of phenotypes, and be run on a whole-genome scale. However, it was originally intended to be used only as needed in an initial filtering step before running the more computationally-intensive -mph 2 analyses. Because of the way -mph1 functions, it does not allow you to ask interesting questions such as which phenotypes are associated with each SNP. To do this more detailed analysis use the -mph 2 option. Note that if you have only a handful of phenotypes, you may be able to run the -mph 2 analysis genome wide on all variants and skip -mph1 all together.\nA quick warning from the creators of mvBIMBAM: the prior used in mvBIMBAM is based on the idea that if a variant is associated with one phenotype, then it is likely associated with multiple phenotypes. That is, it is relatively permissive of associations with multiple phenotypes, and does not attempt to be “skeptical” of additional associations. In this sense it is more suited to hypothesis generation than of hypothesis testing. The prior can be changed to be more skeptical, but this adjustment has not been explored in detail as it is beyond the scope of this tutorial.\n\n\n[1] \"bimbam -g ./inputs/geno_bimbam.txt -p ./inputs/pheno_bimbam.txt -o bimbam_out -mph 2 -f 6 -A 0.05 -A 0.1 -A 0.2 -A 0.4 -r 5254\"\n\n\n[1] \"-bimbam: file 0 has 763 individual and 6 snps\"   \n[2] \"-bimbam: read file 0 again \"                     \n[3] \"-bimbam: number of phenotypes = 6\"               \n[4] \"total = 729\"                                     \n[5] \"output/bimbam_out.mph.txt has been created.\"     \n[6] \"output/bimbam_out.mph.prob.txt has been created.\"\n[7] \"output/bimbam_out.mph.BFs.txt has been created.\" \nattr(,\"status\")\n[1] 1\n\n\nbimbam -g ./inputs/geno_bimbam.txt -p ./inputs/pheno_bimbam.txt \n-o bimbam_out -mph 2 -f 6 -A 0.05 -A 0.1 -A 0.2 -A 0.4 -r 5254\nOnce we run the chunk above, we can then find our output at ./output/bimbam_out.mph.BFs.txt.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html#results",
    "href": "mvbimbam.html#results",
    "title": "4  mvBIMBAM",
    "section": "4.5 Results",
    "text": "4.5 Results\n\n4.5.1 Bayes factors (BF)\nThe evidence against the null hypothesis is the sum of Bayes factors (BF) (log10 scale) of all partitions weighted by a diffuse prior. Let’s read in our BF factor results file to take a look.\n\noptions(pillar.sigfig = 10)\nm1 &lt;- read_delim(\"./output/bimbam_out.mph.BFs.txt\", col_names = FALSE, show_col_types = FALSE) ###CUSTOMIZE** (if output file names are changed in the call object above)\nm1 &lt;- m1 %&gt;% select_if(~any(!is.na(.)))\ncolnames(m1) &lt;- c(\"SNP\", \"BF\", \"BF_All_Partition\", trait_mapping)\nm1 &lt;- data.frame(m1)\n\n\n# View results\npander(m1, digits = 4, caption = \"Bayes Factors\")\n\n\nBayes Factors (continued below)\n\n\n\n\n\n\n\n\n\n\nSNP\nBF\nBF_All_Partition\nAnxiety\nDepression\nFatigue\n\n\n\n\nrs4880\n11.64\n12\n-0.2122\n0.9347\n-0.405\n\n\nrs5746136\n8.751\n9.662\n0.1084\n-0.3045\n0.6435\n\n\nrs1041740\n13.69\n14.4\n12.52\n0.6702\n4.629\n\n\nrs10432782\n4.878\n5.472\n1.619\n1.85\n-0.3186\n\n\nrs4135225\n32.48\n33.08\n0.6325\n1.603\n25.11\n\n\nrs7522705\n1.672\n2.006\n-0.2782\n-0.2978\n-0.2944\n\n\n\n\n\n\n\n\n\n\n\nCognitive.function\nSleepiness\nPain\n\n\n\n\n2.041\n0.02955\n3.437\n\n\n0.2681\n6.421\n0.6853\n\n\n6.156\n0.00889\n-0.2024\n\n\n0.05509\n-0.05979\n-0.1757\n\n\n5.586\n4.684\n11.63\n\n\n0.5971\n-0.3565\n0.2123\n\n\n\n\n\nInterpretation: The above table presents the overall log10 BF for the network, and individual log10 BFs for each trait. Strong evidence of association is defined as log10 BF &gt; 5; suggestive evidence is defined as 1.5 &lt; log10 BF &lt; 5; and negligible evidence is defined as log10 BF &lt; 1.5.\nIn this synthetic data set, we see that all SNPs (rs7522705 less so and rs4135225 more so) appear to play a strong role in this network. rs4880 has suggestive associations with cognitive function and pain; rs5746136 has significant associations with sleepiness; rs1041740 has significant associations with anxiety and cognitive function and a suggestive association with fatigue, etc.\n\n\n4.5.2 Bayesian posterior probabilities of association\nIn addition to log10 BFs, probabilities for no association, direct association, and indirect association are given as output while marginal posterior probabilities of association (MPPA) are calculated by summing the marginal posterior probabilities of direct and indirect association.\n\n# Read in second result file\ns &lt;- readLines(\"./output/bimbam_out.mph.prob.txt\")\n\n# Initialize an empty list to store the matrix for each rs#\nmatrix_list &lt;- vector(\"list\", length(s))\n\n# Process each line\nfor (i in 1:length(s)) {\n  # Split the line by spaces\n  split_values &lt;- strsplit(s[i], \"\\\\s+\")[[1]]\n  # Store the rs# value\n  rs &lt;- split_values[1]\n  \n  m2 &lt;- matrix(na.omit(as.numeric(str_split(s, \" \")[[i]])), nrow = 2)\n  m2 &lt;- rbind(m2, 1 - (m2[1,] + m2[2,]))\n  \n  # Set the column and row names\n  colnames(m2) &lt;- trait_mapping\n  rownames(m2) &lt;- c(paste0(rs, \"_Unassociated\"), paste0(rs, \"_Directly\"), paste0(rs, \"_Indirectly\"))\n\n  # Store the matrix in the list, using rs# as the name\n  matrix_list[[i]] &lt;- list(rs = rs, m2 = m2)\n}\n\n# Combine all matrices into a single matrix\nm2 &lt;- do.call(rbind, lapply(matrix_list, function(x) x$m))\nfor (i in 1:ncol(m2)) {\n  m2[, i] &lt;- as.numeric(gsub(\"\\\"\", \"\", m2[, i]))\n}\n\n\nrs104_dir &lt;- m2[8,1]*100\nrs413_no &lt;- m2[13,5]*100\nrs413_d &lt;- m2[14,5]*100\nrs413_i &lt;- m2[15,5]*100\n\n\npander(m2, digits = 4, caption = \"Bayesian Probabilities\")\n\n\nBayesian Probabilities (continued below)\n\n\n\n\n\n\n\n\n \nAnxiety\nDepression\nFatigue\n\n\n\n\nrs4880_Unassociated\n0.3751\n0.0881\n0.3875\n\n\nrs4880_Directly\n0.3415\n0.9115\n0.2468\n\n\nrs4880_Indirectly\n0.2834\n0.00035\n0.3657\n\n\nrs5746136_Unassociated\n0.1947\n0.3647\n0.07658\n\n\nrs5746136_Directly\n0.8037\n0.5952\n0.9207\n\n\nrs5746136_Indirectly\n0.00154\n0.04015\n0.00272\n\n\nrs1041740_Unassociated\n0\n0.07304\n0\n\n\nrs1041740_Directly\n1\n0.9007\n0.4676\n\n\nrs1041740_Indirectly\n0\n0.02628\n0.5324\n\n\nrs10432782_Unassociated\n0.00504\n0.00493\n0.3862\n\n\nrs10432782_Directly\n0.9831\n0.9789\n0.3531\n\n\nrs10432782_Indirectly\n0.01188\n0.01618\n0.2607\n\n\nrs4135225_Unassociated\n0.08721\n0.01237\n0\n\n\nrs4135225_Directly\n0.9128\n0.532\n1\n\n\nrs4135225_Indirectly\n0\n0.4556\n0\n\n\nrs7522705_Unassociated\n0.4168\n0.54\n0.4684\n\n\nrs7522705_Directly\n0.458\n0.4192\n0.5191\n\n\nrs7522705_Indirectly\n0.1253\n0.04077\n0.01252\n\n\n\n\n\n\n\n\n\n\n\n\n \nCognitive function\nSleepiness\nPain\n\n\n\n\nrs4880_Unassociated\n0.00077\n0.2343\n0.00035\n\n\nrs4880_Directly\n0.9992\n0.358\n0.9997\n\n\nrs4880_Indirectly\n0\n0.4077\n0\n\n\nrs5746136_Unassociated\n0.1642\n0\n0.05097\n\n\nrs5746136_Directly\n0.8279\n0.9999\n0.5256\n\n\nrs5746136_Indirectly\n0.00791\n9e-05\n0.4234\n\n\nrs1041740_Unassociated\n0\n0.2551\n0.2203\n\n\nrs1041740_Directly\n0.9235\n0.7228\n0.3356\n\n\nrs1041740_Indirectly\n0.0765\n0.02212\n0.4441\n\n\nrs10432782_Unassociated\n0.3096\n0.2886\n0.3648\n\n\nrs10432782_Directly\n0.6901\n0.4881\n0.4547\n\n\nrs10432782_Indirectly\n0.00032\n0.2233\n0.1805\n\n\nrs4135225_Unassociated\n0\n0\n0\n\n\nrs4135225_Directly\n0.361\n0.3242\n0.9953\n\n\nrs4135225_Indirectly\n0.639\n0.6758\n0.00466\n\n\nrs7522705_Unassociated\n0.1034\n0.5502\n0.3012\n\n\nrs7522705_Directly\n0.8893\n0.272\n0.6018\n\n\nrs7522705_Indirectly\n0.00732\n0.1778\n0.09697\n\n\n\n\n\nInterpretation: The numbers above can be interpreted as the probability of no association, direct association, or indirect association, which together sum to 1 (i.e., 100%). Both directly and indirectly associated phenotypes are associated with a given genotype, but indirectly associated phenotypes are conditionally independent of the genotype given the presence of a directly associated phenotype in the model.\nFor example, in this synthetic data set, there is a suggested 100% probability that there is a direct association between rs1041740 and anxiety. In addition, while there is a 0% probability of no association between rs4135225 and sleep, the likelihood of direct vs. indirect effects is more split at 32.417% and 67.583%, respectively. While mvBIMBAM doesn’t inform of us what variable indirect associations are conditional on, we can look back at our bnlearn network for more information.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html#save-data-and-results",
    "href": "mvbimbam.html#save-data-and-results",
    "title": "4  mvBIMBAM",
    "section": "4.6 Save data and results",
    "text": "4.6 Save data and results\nTo conclude, save the Bayes factors from the mvBIMBAM results.\n\n4.6.1 mvBIMBAM BFs\n\nsave(m1, m2, file = \"data/mvBimBam_Results.RDdata\") ###CUSTOMIZE** (optional, can change file name of results)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html#discussion",
    "href": "mvbimbam.html#discussion",
    "title": "4  mvBIMBAM",
    "section": "4.7 Discussion",
    "text": "4.7 Discussion\nNote that mvBIMBAM’s default priors are “loose” (the phrase used in the software documentation), meaning associations are detected more liberally. This aligns with our results, where mvBIMBAM identified rs7522705 as suggestively important to the network (1.5 &lt; BF &lt; 5), but none of the individual phenotypes themselves (BFs &lt; 1.5), while bnlearn omitted it completely. It’s worth mentioning that you can modify the default priors to be more conservative (see software documentation), but it is beyond the scope of this guide.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "mvbimbam.html#conclusion",
    "href": "mvbimbam.html#conclusion",
    "title": "4  mvBIMBAM",
    "section": "4.8 Conclusion",
    "text": "4.8 Conclusion\nAnd with that, we conclude our mvBIMBAM tutorial! We hope that this code is documented in enough detail so that you can easily adapt it for your own projects, but feel free to reach out with any questions! -Lacey",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>mvBIMBAM</span>"
    ]
  },
  {
    "objectID": "bnlearnfunctions.html#function-1-fit.the.model",
    "href": "bnlearnfunctions.html#function-1-fit.the.model",
    "title": "Appendix A — Define bnlearn functions",
    "section": "A.1 FUNCTION 1: fit.the.model",
    "text": "A.1 FUNCTION 1: fit.the.model",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Define bnlearn functions</span>"
    ]
  },
  {
    "objectID": "bnlearnfunctions.html#function-2-xval.the.model",
    "href": "bnlearnfunctions.html#function-2-xval.the.model",
    "title": "Appendix A — Define bnlearn functions",
    "section": "Y.1 FUNCTION 2: xval.the.model",
    "text": "Y.1 FUNCTION 2: xval.the.model",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Define bnlearn functions</span>"
    ]
  },
  {
    "objectID": "bnlearnfunctions.html#function-3-run_plot_graph",
    "href": "bnlearnfunctions.html#function-3-run_plot_graph",
    "title": "Appendix A — Define bnlearn functions",
    "section": "y.1 FUNCTION 3: run_plot_graph",
    "text": "y.1 FUNCTION 3: run_plot_graph",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Define bnlearn functions</span>"
    ]
  },
  {
    "objectID": "bnlearnfunctions.html#function-4-match.arcs.and.directions",
    "href": "bnlearnfunctions.html#function-4-match.arcs.and.directions",
    "title": "Appendix A — Define bnlearn functions",
    "section": "�.1 FUNCTION 4: match.arcs.and.directions",
    "text": "�.1 FUNCTION 4: match.arcs.and.directions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Define bnlearn functions</span>"
    ]
  },
  {
    "objectID": "bnlearnfunctions.html#function-5-redraw.graph.labels",
    "href": "bnlearnfunctions.html#function-5-redraw.graph.labels",
    "title": "Appendix A — Define bnlearn functions",
    "section": "�.1 FUNCTION 5: redraw.graph.labels",
    "text": "�.1 FUNCTION 5: redraw.graph.labels",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Define bnlearn functions</span>"
    ]
  },
  {
    "objectID": "bnlearnfunctions.html#function-6-redraw.label.ggnet",
    "href": "bnlearnfunctions.html#function-6-redraw.label.ggnet",
    "title": "Appendix A — Define bnlearn functions",
    "section": "�.1 FUNCTION 6: redraw.label.ggnet",
    "text": "�.1 FUNCTION 6: redraw.label.ggnet",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Define bnlearn functions</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Guide to Multivariate Bayesian Analyses in Nursing Research",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Contact.html",
    "href": "Contact.html",
    "title": "5  Contact information",
    "section": "",
    "text": "Lacey W. Heinsberg, PhD, RN law145@pitt.edu",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Contact information</span>"
    ]
  },
  {
    "objectID": "Troubleshooting.html",
    "href": "Troubleshooting.html",
    "title": "Appendix A — Troubleshooting mvBIMBAM installation",
    "section": "",
    "text": "Note that you need to have GSL (GNU Scientific Library) installed on your machine before you can install mvBIMBAM. GSL is an open-source software library that provides a wide range of mathematical and statistical functions for scientific and numerical computing. If you are having trouble installing mvBIMBAM, lack of GSL seems to be the most frequent cause.\nUsing the terminal, check to see if you have GSL installed on your machine by asking for the version number:\ngsl-config --version\nFor example, on my machine, this command returns “2.7.1”.\nIf GSL is not installed, the simplest way to install it is via homebrew. Homebrew is a popular package manager for macOS and Linux. It provides a convenient way to install, manage, and update software packages and libraries on your computer. Homebrew simplifies the process of setting up development tools and applications.\nFirst, install homebrew using the following terminal command:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\nConfirm that it has been installed, and check for the path:\nbrew --version\nbrew --prefix\nFor example, on my machine, the first command returns “Homebrew 4.0.23” and the second returns “/opt/homebrew”. Note that this tutorial was developed on an Apple silicon (M1) machine. If you have an Apple Intel, the default homebrew install path will be “usr/local/Cellar” or “usr/local”.\nNow let’s move on to installing GSL:\nbrew install gsl\nConfirm install and path:\ngsl-config --version \ngsl-config --prefix\nVoila! (Hopefully :))\nPlease move back to the installation instructions in the README file and try again!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Troubleshooting mvBIMBAM installation</span>"
    ]
  },
  {
    "objectID": "InstallationHack.html",
    "href": "InstallationHack.html",
    "title": "Appendix B — mvBIMBAM Installation Hack",
    "section": "",
    "text": "B.1 Mac\nThe motivation behind modifying the makefile was that during installation, test users were getting the following error:\nwhich suggests there is an issue with the build process. To get around this, we “hacked” a solution by modifying the Makefile (located within the src folder). See a summary below, or a “track changes” comparison in makefile_compare_AppleIntel.docx or makefile_compare_AppleSilicon_M1.docx (located here in the InstallationAppendix folder) for details on how the makefile was modified.\nNote that the makefile changes are different for an Apple Silicon (e.g., 2021 M1) vs. an Apple Intel. If you are not sure which Mac you have, you can click on the apple symbol in the upper left corner of your machine. If you have an Apple silicon, the Chip will be listed as Apple M1 or M2. If you have the Apple Intel, you will see the processor listed as Intel Core i5, i7, or similar.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>mvBIMBAM Installation Hack</span>"
    ]
  },
  {
    "objectID": "InstallationHack.html#mac",
    "href": "InstallationHack.html#mac",
    "title": "Appendix B — mvBIMBAM Installation Hack",
    "section": "",
    "text": "cd src && /Applications/Xcode.app/Contents/Developer/usr/bin/make\ng++ -static-libgcc -DIMPUTATION   -O3 control.o fpmath.o indiv.o diploid.o haploid.o model.o param.o  fp.o -lm libgsl.a libgslcblas.a  -o bimbam\nclang: error: unsupported option '-static-libgcc'\nmake[1]: *** [fp] Error 1\nmake: *** [all] Error 2\n\n\n\nB.1.1 APPLE INTEL INSTRUCTIONS\nCHANGE A Add GSL Compiler and Linker Flags\nCFLAGS += -I/usr/local/Cellar/gsl/2.7.1/include\nLDFLAGS += -L/usr/local/Cellar/gsl/2.7.1/lib\nThese flags include the GSL headers and dynamically specify the location of the GSL libraries on a machine.\nCHANGE B Update LIBS Variable. Specifically, modify:\nLIBS += -lm libgsl.a libgslcblas.a\nto:\nLIBS += -lm -lgsl -lgslcblas\nThis directly links the GSL libraries for math, GSL core, and GSL CBLAS.\nCHANGE C Update Compilation Command: Remove the -static-libgcc flag. Specifically, modify this line:\nfp: fp.o $(OBJS); $(CC) -static-libgcc $(CFLAGS) $(OBJS) fp.o $(LIBS) -o bimbam\nto\nfp: fp.o $(OBJS); $(CC) $(CFLAGS) $(OBJS) fp.o $(LIBS) -o bimbam\nThe -static-libgcc flag is related to linking the GCC (GNU Compiler Collection) runtime libraries statically. However, this flag is not supported by the Clang compiler, which is commonly used on macOS (including Apple Silicon M1 Macs). By removing it, the build rule becomes compatible with Clang and more common macOS build setups.\nA copy of the original Makefile, modified Makefile, and a Word document comparing the two can be found in the Install_Problems folder.\nNote that this problem has been opened as an issue on the mvBIMBAM GitHub page https://github.com/heejungshim/mvBIMBAM/issues/3. Please check there for updates from the program architects.\n\n\nB.1.2 APPLE SILICON (M1)\nCHANGE A Add GSL Compiler and Linker Flags\nCFLAGS += `gsl-config --cflags`\nLIBS += `gsl-config --libs`\nThese flags include the GSL headers and dynamically specify the location of the GSL libraries on your machine.\nCHANGE B Update LIBS Variable: Specifically, modify:\nLIBS += -lm libgsl.a libgslcblas.a\nto:\nLIBS += -lm -lgsl -lgslcblas\nThis directly links the GSL libraries for math, GSL core, and GSL CBLAS.\nCHANGE C Update Compilation Command: The compilation command for the “fp” target should be updated to remove the -static-libgcc flag and add a linker. Specifically, modify:\nfp: fp.o $(OBJS); $(CC) -static-libgcc $(CFLAGS) $(OBJS) fp.o $(LIBS) -o bimbam\nto\nfp: fp.o $(OBJS); $(CC) $(CFLAGS) $(OBJS) fp.o $(LDFLAGS) $(LIBS) -o bimbam\nThe -static-libgcc flag is related to linking the GCC (GNU Compiler Collection) runtime libraries statically. However, this flag is not supported by the Clang compiler, which is commonly used on macOS (including Apple Silicon M1 Macs). By removing it, the build rule becomes compatible with Clang and more common macOS build setups.\nNote also that Apple Silicon also requires the extra $(LDFLAGS) (where Intel does not) which is used to specify linker-related flags and options that may be specific to the architecture of M1 (not needed by Intel).\nA copy of the original Makefile, modified Makefile, and a Word document comparing the two can be found in the Install_Problems folder.\nNote that this problem has been opened as an issue on the mvBIMBAM GitHub page https://github.com/heejungshim/mvBIMBAM/issues/3. Please check there for updates from the program architects.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>mvBIMBAM Installation Hack</span>"
    ]
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "A Guide to Multivariate Bayesian Analyses in Nursing Research",
    "section": "About",
    "text": "About\nThis is a Quarto book created from markdown and executable code using Quarto within RStudio.\nThe goal of this website is to provide detailed code and a fully synthetic example data set to guide nurse scientists and other researchers in conducting multivariate Bayesian analyses to examine associations between correlated phenotypes and single nucleotide polymorphisms (SNPs, i.e., genetic variants).\nNote that this content is available as a website (which you are currently reading) or as a GitHub repository (where all code can be downloaded/edited).\nBook web site: https://lwheinsberg.github.io/mvNUR/\nBook source code/GitHub repository: https://github.com/lwheinsberg/mvNUR",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "A Guide to Multivariate Bayesian Analyses in Nursing Research",
    "section": "Motivation",
    "text": "Motivation\nThe goal of this website is to provide detailed code and a fully synthetic example data set to guide nurse scientists and other researchers in conducting multivariate Bayesian analyses to examine associations between correlated phenotypes and single nucleotide polymorphisms (SNPs, i.e., genetic variants).\nNote that this content is available as a website (which you are currently reading) or as a GitHub repository (https://github.com/lwheinsberg/mvNUR).\nBook web site: https://lwheinsberg.github.io/mvNUR/\nBook source code: https://github.com/lwheinsberg/mvNUR",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#author",
    "href": "index.html#author",
    "title": "A Guide to Multivariate Bayesian Analyses in Nursing Research",
    "section": "Author",
    "text": "Author\nLacey W. Heinsberg, PhD, RN: law145@pitt.edu\nIf you have any questions or comments, please feel free to contact me!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "A Guide to Multivariate Bayesian Analyses in Nursing Research",
    "section": "Copyright",
    "text": "Copyright\nCopyright information:\nCopyright 2023, University of Pittsburgh. All Rights Reserved. License: GPL-2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#from-podium-to-manuscript",
    "href": "index.html#from-podium-to-manuscript",
    "title": "A Guide to Multivariate Bayesian Analyses in Nursing Research",
    "section": "From podium to manuscript",
    "text": "From podium to manuscript\nThis book was created from content presented at the International Society of Nurses in Genetics:\nHeinsberg LW. Multivariate Bayesian Approaches for Analyzing Correlated Phenotypes in Nursing Research. (Expert Lecturer Abstract, Podium). Presented at the International Society of Nurses in Genetics, November 2023, Providence, Rhode Island.\nwhich has been adapted for (hopeful) publication as a manuscript entitled:\nHeinsberg LW, Davis TS, Maher D, Bender CM, Conley YP, Weeks DE. A Guide to Multivariate Bayesian Analyses in Nursing Research. In preparation for submission to Biological Research for Nursing.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#more-information",
    "href": "index.html#more-information",
    "title": "A Guide to Multivariate Bayesian Analyses in Nursing Research",
    "section": "More information",
    "text": "More information\n\nTo learn more about Quarto books visit: https://quarto.org/docs/books/.\nR/Unix basics:\n\nhttps://danieleweeks.github.io/HuGen2071/preparation.html\nhttps://github.com/ajwills72/rminr\nhttps://www.andywills.info/rminr/#beginners\nhttps://www.youtube.com/watch?v=IrDUcdpPmdI\n\nPower calculations\n\nhttps://www.andywills.info/rminr/power-bayesian.html",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html#section",
    "href": "intro.html#section",
    "title": "1  Introduction",
    "section": "1.5 ",
    "text": "1.5",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "A Guide to Multivariate Bayesian Analyses in Nursing Research",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nPlease note that this book was created from content presented at the International Society of Nurses in Genetics:\nHeinsberg LW. Multivariate Bayesian Approaches for Analyzing Correlated Phenotypes in Nursing Research. (Expert Lecturer Abstract, Podium). Presented at the International Society of Nurses in Genetics, November 2023, Providence, Rhode Island\nwhich has been adapted for (hopeful) publication as a manuscript entitled:\nHeinsberg LW, Davis TS, Maher D, Bender CM, Conley YP, Weeks DE. A Guide to Multivariate Bayesian Analyses in Nursing Research. In preparation for submission to Biological Research for Nursing.\nI’d also like to express my gratitude to the following for their support and contributions to this repository:\n\nSupport from the National Institutes of Health under award number K99HD107030 made this project possible, and for that, I’m truly grateful.\nSpecial thanks to Dr. Tara Davis and Mr. Dylan Maher for being “test users” and providing their invaluable feedback on this guide.\nMy deepest gratitude to Dr. Daniel Weeks. Without his guidance and inspiration, I would never have ventured into the world of Bayesian statistics, or pursued many other endeavors I once thought were beyond my capabilities.\n\nI have a Bayesian inference joke but the first three people I told it to didn’t laugh and now I’m not so sure it’s funny. - JSEllenberg.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "prep.html#prepare-data-for-multivariate-analyses",
    "href": "prep.html#prepare-data-for-multivariate-analyses",
    "title": "2  Data preparation",
    "section": "2.3 Prepare data for multivariate analyses",
    "text": "2.3 Prepare data for multivariate analyses\nThe programs we will use for multivariate analyses (bnlearn and mvBIMBAM) require the data to be in a specific format for analysis. Here we are preparing and formatting the data for analysis.\n\n2.3.1 Read in the synthetic data set\nPlease see the introduction for information regarding the example synthetic data set.\n\n# Read in the synthetic data set created for use with this example analysis code\ndf_synth &lt;- read.csv(\"data/BrCa_synthetic.csv\") ###CUSTOMIZE**\nhead(df_synth)\n\n    ID EMO_tscore bdito FAT_tscore paohcif EPSscore pain age education race\n1 1000       47.8     8       46.9       0        5    0  60        18    0\n2 1001       47.8     8       49.2       4       12    3  51        21    0\n3 1002       49.4    18       50.4      16       12    1  57        20    0\n4 1003       45.9     3       38.5       6        2    0  51        16    0\n5 1004       50.8     6       46.9       0        7    1  63        16    0\n6 1005       37.1     0       38.5       0        2    1  59        15    0\n  rs4880 rs5746136 rs1041740 rs10432782 rs4135225 rs7522705\n1      1         0         1          1         1         1\n2      2         1         0          1         0         2\n3      2         1         0          0         0         0\n4      1         1         0          0         1         1\n5      0         1         1          0         1         0\n6      1         0         0          0         1         1\n\n(n &lt;- nrow(df_synth))\n\n[1] 770\n\n# Define the phenotypes (in this case, symptoms) of interest and mapping names \ntraits &lt;- c(\"EMO_tscore\", \"bdito\", \"FAT_tscore\", \"paohcif\", \"EPSscore\", \"pain\") ###CUSTOMIZE**\n# Define a trait mapping object to create custom labels for figures \n# (e.g., EMO_tscore variable represents our measure of Anxiety; bdito represents our measure of depression; etc.)\ntrait_mapping &lt;- c(\"Anxiety\", \"Depression\", \"Fatigue\", \"Cognitive function\", \"Sleepiness\", \"Pain\") ###CUSTOMIZE**\n\n# Create custom labels \ncustom_labels &lt;- setNames(trait_mapping, traits)\n\n# Define variants of interest \ngenes &lt;- c(\"rs4880\", \"rs5746136\", \"rs1041740\", \"rs10432782\", \"rs4135225\", \"rs7522705\") ###CUSTOMIZE**\n\n# Create expanded custom labels \ncustom_labels2 &lt;- c(custom_labels, setNames(genes, genes))\n\n# Create a mapping of node types (for bnlearn)\ndf_vertex_table &lt;- data.frame(\n  vertex.names = c(trait_mapping, genes),\n  type = rep(c(\"Symptom\", \"Genotype\"), each = length(traits)),\n  stringsAsFactors = FALSE\n)\n\nCheck that all variables are numeric or integer.\n\nrs_columns &lt;- grep(\"^rs\", names(df_synth), value = TRUE)\nnon_numeric_rs_columns &lt;- rs_columns[!sapply(df_synth[rs_columns], is.numeric)]\nif (length(non_numeric_rs_columns) &gt; 0) {\n  cat(\"SAFETY CHECK WARNING: The following variables starting with 'rs' are not numeric:\", paste(non_numeric_rs_columns, collapse = \", \"), \"\\n\")\n} else {\n  cat(\"SAFETY CHECK PASSED: All 'rs' variables are numeric.\\n\")\n}\n\nSAFETY CHECK PASSED: All 'rs' variables are numeric.\n\n\nIn brief, the data set focuses on 6 symptoms (EMO_tscore, bdito, FAT_tscore, paohcif, EPSscore, pain) and 6 candidate variants of interest (rs4880, rs5746136, rs1041740, rs10432782, rs4135225, rs7522705) and contains 770 participants.\n\n# Read in a mapping of variable name to informative label\ndict &lt;- read.csv(\"data/BrCa_synthetic_SimpleDict.csv\") ###CUSTOMIZE** (OPTIONAL)\npander(dict, \"Data dictionary\") \n\n\nData dictionary (continued below)\n\n\n\n\n\n\n\nVariable\nLabel\nDescription\n\n\n\n\nEmo_tscore\nAnxiety\nPROMIS Emotional Distress Anxiety (Short Form 8a) - 8 items measuring emotional distress and anxiety (panic, fearfulness, worry, dread, tension,nervousness, restlessness, and somatic symptoms including racing heart and dizziness) in the last 7 days. This instrument generates T-scores, which are standard scores with a mean of 50 and standard deviation of 10 in the U.S. general population. Higher T-scores indicate worse distress and anxiety. T-scores range from 10 to 90.\n\n\nbdito\nDepression\nThe Beck Depression Inventory-II - 21-items measuring severity of depression (i.e., grief, loss, flat affect, withdrawal, mania) over a two-week period. Scores range from 0 to 63, where high scores indicate higher levels or more severe depression.\n\n\nFAT_tscore\nFatigue\nPROMIS Fatigue (Short Form 8a) - 8 items measuring the experience of fatigue and the interference of fatigue on daily activities over the past 7 days. This instrument generates T-scores, which are standard scores with a mean of 50 and standard deviation of 10 in the U.S. general population. Higher T-scores indicate worse fatigue. T-scores range from 10 to 90.\n\n\npaohcif\nCognitive function\nPatient assessment of own cognitive functioning - 33 items measuring self-reported ‘recent’ cognitive function consisting of 5 dimensions: memory, language and communication, use of hands, sensory-perceptual, higher level cognitive and intellectual functioning. Higher scores indicate worse perceived cognitive functioning. Scores range from 0 to 155.\n\n\nEPSscore\nSleepiness\nEpworth Sleepiness Scale - 8 item scale measuring self-reported ‘recent’ daytime sleepiness. Higher score indicate greater daytime sleepiness. Scores range from 0 to 24.\n\n\npain\nPain\nBrief Pain Inventory (Short Form) - 9 items a widely used clinical tool for assessing pain (worst pain in the last 24 hours [0-10], least pain in the last 24 hours [0-10], pain on average [0-10], paing at the time of the interview [0-10], pain relief from treatment(s) in the last 24 hours [0%-100%]). Higher scores indicate higher levels of pain, each item ranges from 0-10.\n\n\nrs4880\nVariant 1\nSOD2 gene, hg19 postion chr6: 160113872\n\n\nrs5746136\nVariant 2\nSOD2 gene, hg19 postiion chr6: 160103084\n\n\nrs1041740\nVariant 3\nSOD1 gene, hg19 postiion chr21: 33040162\n\n\nrs10432782\nVariant 4\nSOD1 gene, hg19 postiion chr21: 33036391\n\n\nrs4135225\nVariant 5\nTXN gene, hg19 postiion chr9: 113006691\n\n\nrs7522705\nVariant 6\nPRDX1 gene, hg19 postiion chr1: 45992300\n\n\nrace\nRace\nSelf-identified race, 0=White, 1=Black\n\n\nage\nAge\nAge in years\n\n\neducation\nEducation\nSelf-reported years of education\n\n\n\n\n\n\n\n\n\n\nType\nCitation\n\n\n\n\nNumeric\nPilkonis, P.A. et al. (2011) Item banks for measureing emotional distress from the patient-reported outcomes measurement information system (PROMIS): Depression, Anxiety, and Anger, Assesssment, 18(3), 263-283\n\n\nNumeric\nBeck, A.T. et al. (1996) Beck Depression Inventory-II. San Antonio: The Psychological Corporation\n\n\nNumeric\nCell, D. et al. (2016) PROMIS fatigue item bank had clinical validity across diverse chronic conditions. Journal of Clinical Epidemiology, 73, 128-134\n\n\nNumeric\nChelune, G. J. et al. (1986) Neuropsychological and personality correlates of patients’ complaints of disability. Advances in clinical Neuropsychology, 1986:95-126\n\n\nNumeric\nJohns MW. A new method for measuring daytime sleepiness: The Epworth Sleepiness Scale. Sleep 1991; 14(6):540-5\n\n\nNumeric\nCleeland, C.S. et al. (2009). Pain assessment: Global use of the Brief Pain Inventory. Annals, Academy of Medicine, Sigapore, 23(2), 129-138.\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\nNumeric, encoded value\n\n\n\nNumeric\n\n\n\nNumeric\n\n\n\n\n\n\n\n\n2.3.2 Examine correlation structure of the symptoms\n\n# Subset the dataset to include only the selected traits\nsubset_df &lt;- df_synth[traits]\n# Calculate the correlation matrix\ncor_matrix &lt;- cor(subset_df, use = \"complete.obs\")\n# Define custom labels for rows and columns\n# Update row and column names using custom labels\nrownames(cor_matrix) &lt;- custom_labels[rownames(cor_matrix)]\ncolnames(cor_matrix) &lt;- custom_labels[colnames(cor_matrix)]\n# Create a correlation plot\ncorrplot(cor_matrix, method = \"circle\", type = \"lower\", tl.col = \"black\", tl.srt = 45)\n\n\n\n\n\n\n\n\n\n\n2.3.3 Examine correlation structure of SNPs\n\n# Subset the dataset to include only the selected traits\nsubset_df &lt;- df_synth[genes]\n# Calculate the correlation matrix\ncor_matrix &lt;- cor(subset_df, use = \"complete.obs\")\n# Create a correlation plot\ncorrplot(cor_matrix, method = \"circle\", type = \"lower\", tl.col = \"black\", tl.srt = 45)\n\n\n\n\n\n\n\n\n\n\n2.3.4 Summarize missing data\n\nmissing_data_table &lt;- df_synth %&gt;%\n  summarise(across(everything(), ~sum(is.na(.)))) %&gt;% # Count NA values in each column\n  gather(key = \"Column\", value = \"Number_of_NAs\") %&gt;% # Convert to long format\n  arrange(desc(Number_of_NAs)) # Sort by the number of NAs\npander(missing_data_table)\n\n\n\n\n\n\n\n\nColumn\nNumber_of_NAs\n\n\n\n\nEMO_tscore\n7\n\n\nID\n0\n\n\nbdito\n0\n\n\nFAT_tscore\n0\n\n\npaohcif\n0\n\n\nEPSscore\n0\n\n\npain\n0\n\n\nage\n0\n\n\neducation\n0\n\n\nrace\n0\n\n\nrs4880\n0\n\n\nrs5746136\n0\n\n\nrs1041740\n0\n\n\nrs10432782\n0\n\n\nrs4135225\n0\n\n\nrs7522705\n0\n\n\n\n\n\n\n\n2.3.5 Clean up data\nFirst, let’s prepare our data sets. Currently, the software we are using does not allow missing data for multivariate phenotype analysis, so select complete cases only. We will also set up a few data frames in preparation to regress out variation related to our covariates of interest (in this example, age and race).\n\ndf_i1_regress: contains all variables of interest ordered and filtered for complete cases\n\ndf_i1: contains all variables except the covariates that will be regressed out below (in this example, age and race)\n\ndf_synth: Recode 0, 1, 2 genotypes to AA, AB, BB for later use in mvBIMBAM\n\n\n# The first data frame (df_i1_regress) contains all variables of interest ordered \n# and filtered for complete cases\ndf_i1_regress &lt;- df_synth %&gt;% \n  select(all_of(genes), \n         all_of(traits),\n         race, ###CUSTOMIZE** (covariate names, replacing age and race)\n         age) %&gt;% ###CUSTOMIZE** (covariate names, replacing age and race)\n  filter(complete.cases(.))\n(n &lt;- nrow(df_i1_regress))\n\n[1] 763\n\n# The second data frame (df_i1) contains all variables except the covariates that\n# will be regressed out (in this example, age and race)\ndf_i1 &lt;- df_i1_regress %&gt;% \n  select(all_of(genes), all_of(traits)) %&gt;% \n  filter(complete.cases(.))\n\n# Recode 0, 1, 2 genotypes to AA, AB, BB for later use in mvBIMBAM \ndf_synth &lt;- df_synth %&gt;% \n  mutate_at(\n    .vars = vars(starts_with(\"rs\")),\n    .funs = list(~ case_when(\n      . == 2 ~ \"BB\",\n      . == 1 ~ \"AB\",\n      . == 0 ~ \"AA\"\n    ))\n  )\n\n# Create Genotype (G) and Phenotype (Y) matrices\nG &lt;- as.matrix(df_i1 %&gt;% select(all_of(genes)))\nhead(G)\n\n     rs4880 rs5746136 rs1041740 rs10432782 rs4135225 rs7522705\n[1,]      1         0         1          1         1         1\n[2,]      2         1         0          1         0         2\n[3,]      2         1         0          0         0         0\n[4,]      1         1         0          0         1         1\n[5,]      0         1         1          0         1         0\n[6,]      1         0         0          0         1         1\n\nY &lt;- as.matrix(df_i1 %&gt;% select(all_of(traits)))\nhead(Y)\n\n     EMO_tscore bdito FAT_tscore paohcif EPSscore pain\n[1,]       47.8     8       46.9       0        5    0\n[2,]       47.8     8       49.2       4       12    3\n[3,]       49.4    18       50.4      16       12    1\n[4,]       45.9     3       38.5       6        2    0\n[5,]       50.8     6       46.9       0        7    1\n[6,]       37.1     0       38.5       0        2    1\n\n\nThere are 763 participants with complete data that we will retain for our analyses.\n\n\n2.3.6 Normalize and adjust data for covariates\nIn this example, we are adjusting our phenotypes of interest for the covariates age and race using ordinary linear regression models. If adapting this code for your own work, manually edit the covariate names in the f_quatile_norm_resid() function. Note that the sensitivity of the Bayesian multivariate mvBIMBAM framework to outlier values and non-normality also necessitates the normalization of phenotypes. As shown below, residualized phenotypes (i.e., adjusted for age/race) are order quantile-normalized.\n\n2.3.6.1 Create adjustment/normalization functions\nWe now create a function to perform residual adjustment for covariates (in this example, we are adjusting for age and race):\n\nf_quantile_norm_resid &lt;- function(Y, df) {\n  {o &lt;- apply(Y, 2, function(x) resid(lm(x ~ age + race, data = df)))} ###CUSTOMIZE** (covariate names, replacing age and race)\n  return(o)\n}\n\nIf adapting this code above for your own work, edit the x ~ age + race regression formula to adjust for covariates of interest, replacing age and race with your covariate variable names.\nWe now create function to ‘super quantile normalize’ the data:\n\nf_quantile_normalize_adjust &lt;- function(Y, data, ...) {\n  # Quantile normalize\n  Y_qn &lt;- normalize.quantiles(Y)\n  # Fit Y ~ age + race, extra residual (using function created above)\n  Y_qn_resid &lt;- f_quantile_norm_resid(Y = Y_qn, df = data, ...) \n  # Quantile normalize the residual\n  Y_qn_resid_qn &lt;- data.frame(normalize.quantiles(Y_qn_resid))\n  return(Y_qn_resid_qn)\n}\n\n\n\n2.3.6.2 Apply functions to perform normalization and covariate adjustment\n\n# Create a quantile normalized adjusted Y data frame (i.e., quantile normalization \n# and covariate adjustment is performed in one fell swoop)\nqn_resid_Y &lt;- f_quantile_normalize_adjust(Y, data = df_i1_regress)\n# Create a copy of this data frame for use later in this workflow \nqn_resid_Y_b &lt;- qn_resid_Y \n# Rename the columns of the quantile normalized data frame to match the \n# phenotypes of interest  \nnames(qn_resid_Y) &lt;- traits\nhead(qn_resid_Y)\n\n  EMO_tscore       bdito FAT_tscore   paohcif  EPSscore      pain\n1 -0.8851885  2.30362054  -3.330215 -5.645429 -3.414409 -6.012957\n2 -1.9542886  0.09188708  -3.221254 -1.577718  7.196097  1.066255\n3 -0.1561693  9.13047401  -2.133030 13.281734  8.530244 -3.592499\n4 -3.4144091 -6.10527417  -7.413173  1.066255 -8.598853 -7.199561\n5  1.8913640  0.83681075  -2.840231 -4.802835  1.891364 -1.847911\n6 -6.1052742 -8.14287258  -6.446351 -6.057697 -8.142873 -2.818185\n\n\nNote: For one test user (DM), the above chunk threw the error:\nError in normalize.quantiles(Y) : \nERROR; return code from pthread_create() is 22\nThis issue was resolved by updating Rstudio to the latest version.\n\n\n\n2.3.7 Remove outliers\nObservations in violation of multivariate normality at an alpha=0.01 level based on Mahalanobis distance-based test statistics are now removed to avoid spurious conclusions.\n\n2.3.7.1 Write a function to calculate Mahalanobis distance\n\n# Create a function to calculate Mahalanobis distance\ngetMD &lt;- function(x) {\n  Sx &lt;- cov(x)\n  m &lt;- mahalanobis(x, colMeans(x), Sx)\n  return(m)\n}\n\n\n\n2.3.7.2 Apply function to identify outliers\n\n# Drop individuals with data violating multivariate normality at alpha = 0.01\ni_keep &lt;- which(pchisq(getMD(qn_resid_Y_b), df = dim(Y)[2]) &gt; 0.01)\n\n\n\n\n2.3.8 Create a summary\n\n# Record sample sizes in a summary table\ntable1 &lt;- data.frame(study=rep(NA,1),N.traits=NA,N.variants=NA,N.total=NA,n.complete=NA,n.used=NA)\ni &lt;- 1\ntable1[i,\"study\"] &lt;- \"Study Name\" ###CUSTOMIZE** (study name)\ntable1[i,\"N.total\"] &lt;- nrow(df_synth)\ntable1[i,\"n.complete\"] &lt;- nrow(qn_resid_Y)\ntable1[i,\"n.used\"]  &lt;- nrow(qn_resid_Y[i_keep, ])\ntable1[i,\"N.traits\"] &lt;- ncol(qn_resid_Y)\ntable1[i,\"N.variants\"] &lt;- length(genes)\ntable1[i,]\n\n       study N.traits N.variants N.total n.complete n.used\n1 Study Name        6          6     770        763    763\n\n# Print number of observations due to violation of multivariate normality \ncat(dim(Y)[1] - length(i_keep), \" Obs removed due to violation of MV-Normality\")\n\n0  Obs removed due to violation of MV-Normality\n\n# Add to summary table\ntable1$n.removed &lt;- table1$N.total - table1$n.used\ntable1$percent.removed &lt;- round(100*table1$n.removed/table1$N.total,2)\n\n\npander(table1,caption=\"Sample sizes\")\n\n\nSample sizes (continued below)\n\n\n\n\n\n\n\n\n\n\n\nstudy\nN.traits\nN.variants\nN.total\nn.complete\nn.used\nn.removed\n\n\n\n\nStudy Name\n6\n6\n770\n763\n763\n7\n\n\n\n\n\n\n\n\n\npercent.removed\n\n\n\n\n0.91\n\n\n\n\n\n\n\n2.3.9 Prepare and save final files\n\n2.3.9.1 Data used in both programs\n\n# Check for data directory; if not present, create it \nif (!dir.exists(\"./data\")) {\n  dir.create(\"./data\")\n}\n\n# Write data \nsave(traits, genes, trait_mapping, custom_labels, custom_labels2, df_vertex_table, file = \"./data/TraitsGenes.RData\") ###CUSTOMIZE** (optional, file name)\n\n\n\n2.3.9.2 mvBIMBAM\n\n# Write phenotypes to a text file for use in mvBIMBAM \nif (!dir.exists(\"./inputs\")) {\n  dir.create(\"./inputs\")\n}\nwrite.table(round(qn_resid_Y[i_keep,], 8), \n            \"./inputs/pheno_bimbam.txt\", sep = \" \", ###CUSTOMIZE** (optional, file name)\n            row.names = F, col.names = F)\n\n# Refine genotype data for mvBIMBAM and write file\nGeno_write &lt;- df_synth %&gt;% select(all_of(genes), all_of(traits)) %&gt;%\n  filter(complete.cases(.)) %&gt;%\n  select(all_of(genes)) %&gt;%\n  {.[i_keep,]} # Apply i_keep matrix here to retain non-outlying participants\n\n# Grep rs column numbers to create the geno_string file required for mvBIMBAM format\nrs_cols &lt;- grep(\"^rs\", colnames(df_synth), value = TRUE)\n\n# Create geno_string format required for mvBIMBAM, filtering data set for only i_keep participants\nGeno_String &lt;- map(rs_cols, ~ {\n  Geno_write &lt;- df_synth %&gt;%\n    select(all_of(.x), all_of(traits)) %&gt;%\n    filter(complete.cases(.)) %&gt;%\n    select(all_of(.x))%&gt;%\n    {.[i_keep,]}\n  \n  # Creating the Geno_String for each SNP rsID  \n  Geno_String &lt;- paste0(unlist(c(Geno_write)), collapse = \",\")\n  Geno_String &lt;- paste0(.x, \",\", Geno_String)\n  \n  Geno_String\n}) \n\n# Polish geno_string for mvBIMBAM\nfinal_Geno_String &lt;- paste0(unlist(Geno_String), collapse = \"\\n\")\nM &lt;- length(unlist(strsplit(Geno_String[[1]], \",\"))) - 1\nN &lt;- length(Geno_String)\nfinal_Geno_String &lt;- paste0(M, \"\\n\", N, \"\\n\", final_Geno_String)\n\n# Write it out \nwriteLines(final_Geno_String, con = \"./inputs/geno_bimbam.txt\", sep = \"\") ###CUSTOMIZE** (optional, file name)\n\n\n\n2.3.9.3 bnlearn\n\n# Curate bnlearn data (convert AA/BB coding back to additive) \nGeno_write2 &lt;- Geno_write %&gt;%\n    mutate_at(\n    .vars = vars(starts_with(\"rs\")),\n    .funs = list(~ case_when(\n      . ==  \"BB\" ~ 2,\n      . == \"AB\" ~ 1,\n      . ==  \"AA\" ~ 0\n    ))\n  )\n\n# Create merged data frame\nbnlearn_data &lt;- data.frame(Geno_write2, round(qn_resid_Y[i_keep,], 8))\n\n# The package to learn the Bayesian networks (bnlearn) does not support integer data,\n# so convert integer columns to numeric\nbnlearn_data[sapply(bnlearn_data, class) == \"integer\"] &lt;- \n  sapply(bnlearn_data[sapply(bnlearn_data, class) == \"integer\"], as.numeric)\n\n# Write data for bnlearn\nsaveRDS(bnlearn_data, file = \"data/QuantNorm.rds\") ###CUSTOMIZE** (optional, file name)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  }
]